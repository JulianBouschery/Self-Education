{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38079b6c-c186-4c57-953b-2e8f016b79ec",
   "metadata": {},
   "source": [
    "# Beispiel für Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca37bb-13b4-420d-92e3-b17269364b69",
   "metadata": {},
   "source": [
    "Noch nicht fertig!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486f788-b79a-4826-af2e-db5a7c52eb05",
   "metadata": {},
   "source": [
    "### Beispiel:\n",
    "Angenommen, wir haben ein neuronales Netzwerk, das eine **Einzelne Eingabe** (x) mit einem **Ausgang** (y) verknüpft. Das Netzwerk hat:\n",
    "- Eine Eingabeschicht mit 1 Neuron (x)\n",
    "- Eine versteckte Schicht mit 2 Neuronen (h1 und h2)\n",
    "- Eine Ausgabeschicht mit 1 Neuron (y_pred)\n",
    "\n",
    "### Schritt 1: Vorwärtsdurchlauf\n",
    "1. **Initialisierung der Gewichte**:\n",
    "   - $w_{xh1} = 0.5$\n",
    "   - $w_{xh2} = -0.5$\n",
    "   - $w_{h1y} = 1.0$\n",
    "   - $w_{h2y} = -1.0$\n",
    "--- \n",
    "2. **Eingabe**: $ x = 1 $\n",
    "---\n",
    "3. **Aktivierung der Neuronen**:\n",
    "   - $h1 = \\sigma(w_{xh1} \\cdot x) = \\sigma(0.5 \\cdot 1) = \\sigma(0.5) \\approx 0.62$ (Sigmoid-Aktivierungsfunktion)\n",
    "   - $h2 = \\sigma(w_{xh2} \\cdot x) = \\sigma(-0.5 \\cdot 1) = \\sigma(-0.5) \\approx 0.38$\n",
    "---\n",
    "4. **Ausgabe**:\n",
    "   - $ y_{\\text{pred}} = \\sigma(w_{h1y} \\cdot h1 + w_{h2y} \\cdot h2) = \\sigma(1.0 \\cdot 0.62 - 1.0 \\cdot 0.38) = \\sigma(0.24) \\approx 0.56$\n",
    "\n",
    "### Schritt 2: Fehlerberechnung\n",
    "Angenommen, das **tatsächliche** Ziel ist $y = 1$.\n",
    "\n",
    "- **Fehler** (Loss) mit der **Mean Squared Error (MSE)**-Funktion:\n",
    "  $$\n",
    "  \\text{Loss} = \\frac{1}{2} (y - y_{\\text{pred}})^2 = \\frac{1}{2} (1 - 0.56)^2 \\approx 0.097\n",
    "  $$\n",
    "\n",
    "### Schritt 3: Rückwärtsausbreitung\n",
    "1. **Gradient der Verlustfunktion**:\n",
    "   - Der Gradient der Verlustfunktion bzgl. der Ausgabe:\n",
    "   $$\n",
    "   \\frac{\\partial \\text{Loss}}{\\partial y_{\\text{pred}}} = y_{\\text{pred}} - y \\approx 0.56 - 1 = -0.44\n",
    "   $$\n",
    "\n",
    "2. **Gradient bzgl. der Gewichte in der Ausgabeschicht**:\n",
    "   - Für $w_{h1y}$:\n",
    "   $$\n",
    "   \\frac{\\partial y_{\\text{pred}}}{\\partial w_{h1y}} = h1 \\quad \\Rightarrow \\quad \\frac{\\partial \\text{Loss}}{\\partial w_{h1y}} = \\frac{\\partial \\text{Loss}}{\\partial y_{\\text{pred}}} \\cdot \\frac{\\partial y_{\\text{pred}}}{\\partial w_{h1y}} = -0.44 \\cdot 0.62 \\approx -0.27\n",
    "   $$\n",
    "\n",
    "   - Für $w_{h2y}$:\n",
    "   $$\n",
    "   \\frac{\\partial y_{\\text{pred}}}{\\partial w_{h2y}} = h2 \\quad \\Rightarrow \\quad \\frac{\\partial \\text{Loss}}{\\partial w_{h2y}} = -0.44 \\cdot 0.38 \\approx -0.17\n",
    "   $$\n",
    "\n",
    "3. **Gradient bzgl. der versteckten Schicht**:\n",
    "   - Der Gradient bzgl. der Neuronen in der versteckten Schicht wird unter Berücksichtigung der Gewichtung berechnet.\n",
    "\n",
    "### Schritt 4: Gewichtsaktualisierung\n",
    "Angenommen, wir verwenden eine Lernrate von $ \\eta = 0.1 $.\n",
    "\n",
    "- Update für $w_{h1y}$:\n",
    "  $$\n",
    "  w_{h1y} = w_{h1y} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w_{h1y}} = 1.0 - 0.1 \\cdot (-0.27) \\approx 1.027\n",
    "  $$\n",
    "\n",
    "- Update für $w_{h2y}$:\n",
    "  $$\n",
    "  w_{h2y} = w_{h2y} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w_{h2y}} = -1.0 - 0.1 \\cdot (-0.17) \\approx -0.983\n",
    "  $$\n",
    "\n",
    "### Zusammenfassung\n",
    "Dies ist ein vereinfachtes Beispiel für den Backpropagation-Prozess. In der Praxis werden viele Datenpunkte durch das Netzwerk propagiert, und die Gewichte werden nach jedem Batch oder über mehrere Epochen hinweg aktualisiert, um das Netzwerk zu optimieren und die Vorhersagen zu verbessern.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b072634-2ccc-4149-91b4-b74dedcaf309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
