{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149d3331-89d7-4bee-83c5-8dd515c3f3d5",
   "metadata": {},
   "source": [
    "# Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a183be6-b6ee-469b-b582-8caa7e1da097",
   "metadata": {},
   "source": [
    "Die `Pipeline()`-Funktion aus dem Modul `sklearn` (Scikit-learn) wird verwendet, um eine Abfolge von Verarbeitungsschritten für maschinelles Lernen in einem einzigen Objekt zu kapseln. Dies ist besonders nützlich, um den Code sauber und übersichtlich zu halten, insbesondere wenn man mehrere Schritte durchlaufen muss, wie etwa Datenvorverarbeitung und Modelltraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fd9be-fa3c-4108-ba31-6bee8dabead0",
   "metadata": {},
   "source": [
    "### Wofür wird `Pipeline()` genutzt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93841f39-2245-4f59-860d-f3cc21445be3",
   "metadata": {},
   "source": [
    "- **Automatisierung mehrerer Schritte**: Anstatt die Datenvorverarbeitung und das Training manuell in mehreren Schritten durchzuführen, kann man alle Schritte in einer Pipeline definieren und diese zusammen anwenden.\n",
    "- **Vermeidung von Datenlecks**: Wenn man separate Schritte für Vorverarbeitung und Modelltraining hat, kann es passieren, dass Datenlecks entstehen. Eine Pipeline verhindert das, indem sie sicherstellt, dass alle Schritte in der richtigen Reihenfolge ausgeführt werden und nur auf den Trainingssatz angewendet werden.\n",
    "- **Einfachere Cross-Validation**: Mit einer Pipeline kann man sicherstellen, dass die Vorverarbeitung in jedem [Fold](../Fachwörter/Fold.ipynb) einer Cross-Validation korrekt angewendet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888fb47-83c3-40d3-96e7-1d6cd5d4017f",
   "metadata": {},
   "source": [
    "### Aufbau einer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7b3a1-faad-4410-b5df-f8c1a010585e",
   "metadata": {},
   "source": [
    "Eine Pipeline besteht aus einer Abfolge von **Transformern** und einem **Estimator**. \n",
    "\n",
    "- **Transformer**: Jeder Schritt (außer der letzte) muss ein Transformer sein, also eine Funktion oder ein Modell, das Daten umwandelt (z. B. Skalieren, One-Hot-Encoding).\n",
    "- **Estimator**: Der letzte Schritt muss ein Estimator sein, also ein Modell, das die finale Vorhersage trifft (z. B. ein Klassifikator oder ein Regressor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc47103-a719-49c1-b6e6-f758b3c4063c",
   "metadata": {},
   "source": [
    "### Beispielcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3b700-128d-4c99-b274-0e09e75a3a17",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Beispiel Datensatz laden\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Daten in Trainings- und Testsets aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pipeline erstellen\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Schritt 1: Daten skalieren\n",
    "    ('classifier', LogisticRegression())  # Schritt 2: Klassifikator trainieren\n",
    "])\n",
    "\n",
    "# Pipeline auf die Trainingsdaten anwenden\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen treffen\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcdcf1-435a-4ccd-b0b9-26364fa85a6e",
   "metadata": {},
   "source": [
    "### Erklärung:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b27bb-4a38-48f2-9bc1-3f6cd669bd03",
   "metadata": {},
   "source": [
    "1. **StandardScaler**: Skaliert die Eingabedaten, sodass sie einen Mittelwert von 0 und eine Standardabweichung von 1 haben.\n",
    "2. **LogisticRegression**: Wird als Klassifikator verwendet, um das trainierte Modell zu erstellen.\n",
    "3. **Pipeline**: Fasst den Vorverarbeitungsschritt (`scaler`) und den Klassifikator (`classifier`) zusammen, sodass beide Schritte in einem Aufruf (`pipeline.fit()`) durchgeführt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78660d4-20ca-4a18-bf19-a32eb97359c2",
   "metadata": {},
   "source": [
    "### Vorteile von `Pipeline()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4b1c8-e824-402d-84c7-d9383bd13e38",
   "metadata": {},
   "source": [
    "- **Sauberer Code**: Alle Schritte in einer einzigen Pipeline.\n",
    "- **Wiederverwendbar**: Die Pipeline kann einfach wiederholt auf verschiedene Daten angewendet werden.\n",
    "- **Vermeidung von Fehlern**: Die Pipeline behandelt Datenlecks und sorgt dafür, dass Cross-Validation korrekt durchgeführt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0299c4e-ea72-4b17-937e-04402e475e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
