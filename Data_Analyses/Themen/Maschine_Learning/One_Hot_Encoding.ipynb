{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5fdadf-23c3-4dd7-905b-5f41f8ffe007",
   "metadata": {},
   "source": [
    "# One Hot-Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d664ce8-91b9-403f-b20b-bd5c61caa4d3",
   "metadata": {},
   "source": [
    "**One-Hot-Encoding** ist eine Technik, die verwendet wird, um kategoriale Daten (also Daten, die aus diskreten Kategorien bestehen) in eine numerische Form zu überführen, die von maschinellen Lernalgorithmen verarbeitet werden kann.\n",
    "\n",
    "### Prinzip:\n",
    "\n",
    "Angenommen, du hast eine Liste von Kategorien, wie z.B. Farben:\n",
    "\n",
    "- Rot\n",
    "- Blau\n",
    "- Grün\n",
    "\n",
    "Diese können nicht direkt in Modelle wie neuronale Netze oder Entscheidungsbäume eingegeben werden, da diese nur mit numerischen Werten arbeiten. Der Trick bei One-Hot-Encoding besteht darin, jede Kategorie in eine binäre (0 oder 1) Form umzuwandeln.\n",
    "\n",
    "#### Beispiel:\n",
    "\n",
    "Für die Liste der Farben:\n",
    "\n",
    "- **Rot**\n",
    "- **Blau**\n",
    "- **Grün**\n",
    "\n",
    "würde das One-Hot-Encoding so aussehen:\n",
    "\n",
    "| Farbe | Rot | Blau | Grün |\n",
    "|-------|-----|------|------|\n",
    "| Rot   |  1  |  0   |  0   |\n",
    "| Blau  |  0  |  1   |  0   |\n",
    "| Grün  |  0  |  0   |  1   |\n",
    "\n",
    "Jede Kategorie wird durch einen Vektor dargestellt, bei dem nur eine Stelle auf \"1\" gesetzt ist (die der jeweiligen Kategorie entspricht) und alle anderen Stellen auf \"0\".\n",
    "\n",
    "### Warum verwendet man One-Hot-Encoding?\n",
    "\n",
    "One-Hot-Encoding ist besonders wichtig, weil es keine implizite Reihenfolge zwischen den Kategorien erzeugt. Wenn man stattdessen den Kategorien numerische Werte zuweisen würde (z.B. Rot = 1, Blau = 2, Grün = 3), könnte der Algorithmus fälschlicherweise annehmen, dass \"Grün\" mehr Gewicht hat als \"Rot\", was in den meisten Fällen keinen Sinn ergibt.\n",
    "\n",
    "### Python-Beispiel:\n",
    "\n",
    "In Python kann man One-Hot-Encoding z.B. mit der Bibliothek `pandas` oder `sklearn` umsetzen.\n",
    "\n",
    "Mit `pandas`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Beispielkategorien\n",
    "farben = ['Rot', 'Blau', 'Grün', 'Blau', 'Grün', 'Rot']\n",
    "\n",
    "# Umwandlung in One-Hot-Encoded DataFrame\n",
    "df = pd.get_dummies(farben)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "   Blau  Grün  Rot\n",
    "0     0     0    1\n",
    "1     1     0    0\n",
    "2     0     1    0\n",
    "3     1     0    0\n",
    "4     0     1    0\n",
    "5     0     0    1\n",
    "```\n",
    "\n",
    "Hier wird jede Farbe in ein eigenes Binärfeld umgewandelt.\n",
    "\n",
    "### Zusammenfassung:\n",
    "\n",
    "One-Hot-Encoding ist nützlich, um kategoriale Variablen in ein Format zu bringen, das von maschinellen Lernmodellen verstanden wird, ohne dass eine unerwünschte Reihenfolge oder Gewichtung zwischen den Kategorien entsteht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225cabb-e4a4-41c2-abfd-4724bd7c9505",
   "metadata": {},
   "source": [
    "# (Mieses) Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb7ddd7-7056-46fc-b8c5-d8f67e75b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kodierte Features:\n",
      "   Farbe_Blau  Farbe_Grün  Farbe_Rot  Größe_L  Größe_M  Größe_S\n",
      "0         0.0         0.0        1.0      0.0      0.0      1.0\n",
      "1         0.0         1.0        0.0      0.0      1.0      0.0\n",
      "2         1.0         0.0        0.0      1.0      0.0      0.0\n",
      "3         0.0         1.0        0.0      1.0      0.0      0.0\n",
      "4         0.0         0.0        1.0      0.0      0.0      1.0\n",
      "\n",
      "Mean Squared Error: 13.89\n",
      "\n",
      "Vergleich von tatsächlichen und vorhergesagten Preisen:\n",
      "   Tatsächlicher Preis  Vorhergesagter Preis\n",
      "8                   20             15.000000\n",
      "1                   15             13.333333\n",
      "\n",
      "Vorhergesagter Preis für neue Daten: 18.33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# Beispiel-Datensatz erstellen\n",
    "data = pd.DataFrame({\n",
    "    'Farbe': ['Rot', 'Grün', 'Blau', 'Grün', 'Rot', 'Blau', 'Rot', 'Blau', 'Grün', 'Rot'],\n",
    "    'Größe': ['S', 'M', 'L', 'L', 'S', 'M', 'M', 'S', 'L', 'M'],\n",
    "    'Preis': [10, 15, 20, 15, 10, 20, 10, 15, 20, 10],\n",
    "    'Klassifizierung': [0, 1, 0, 1, 0, 1, 0, 1, 1, 0]  # Zielwert (z.B. 0 = nicht kaufen, 1 = kaufen)\n",
    "})\n",
    " \n",
    "# Features und Zielvariable trennen\n",
    "X = data[['Farbe', 'Größe']]\n",
    "y = data['Preis']\n",
    " \n",
    "# One-Hot-Encoding für die kategorischen Features 'Farbe' und 'Größe' ohne Drop-First\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    " \n",
    "# Abrufen der Spaltennamen nach dem Encoding\n",
    "encoded_columns = encoder.get_feature_names_out(['Farbe', 'Größe'])\n",
    " \n",
    "# Kodierte Features in einen DataFrame umwandeln\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_columns)\n",
    " \n",
    "# Kodierte Features anzeigen\n",
    "print(\"Kodierte Features:\")\n",
    "print(X_encoded_df.head())\n",
    " \n",
    "# Daten in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded_df, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Lineares Regressionsmodell erstellen und trainieren\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# Vorhersagen auf Testdaten\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# MSE (Mean Squared Error) berechnen\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nMean Squared Error: {mse:.2f}\")\n",
    " \n",
    "# Vergleich von tatsächlichen und vorhergesagten Werten\n",
    "results = pd.DataFrame({'Tatsächlicher Preis': y_test, 'Vorhergesagter Preis': y_pred})\n",
    "print(\"\\nVergleich von tatsächlichen und vorhergesagten Preisen:\")\n",
    "print(results)\n",
    " \n",
    "# Vorhersage für neue Daten\n",
    "new_data = pd.DataFrame({\n",
    "    'Farbe_Blau': [1],\n",
    "    'Farbe_Grün': [0],\n",
    "    'Farbe_Rot': [0],\n",
    "    'Größe_L': [0],\n",
    "    'Größe_M': [1],\n",
    "    'Größe_S': [0]\n",
    "})\n",
    " \n",
    "# Spaltenreihenfolge sicherstellen\n",
    "new_data = new_data[encoded_columns]\n",
    " \n",
    "# Vorhersage durchführen\n",
    "price_prediction = model.predict(new_data)\n",
    "print(f\"\\nVorhergesagter Preis für neue Daten: {price_prediction[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf7172-4d94-4560-b2ac-3ef70c7581e6",
   "metadata": {},
   "source": [
    "# Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640669e7-8561-4b22-ac1c-a67b8b50a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
