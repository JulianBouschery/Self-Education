{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b768d5-2e4c-4ebd-9a2d-7c3f3ec9eecd",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744f883-20c6-44d9-9734-e59cd5fa2fee",
   "metadata": {},
   "source": [
    "Ganz kurz formuliert: Ridge Regression ist wie lineare Regression nur, dass es das Overfitting etwas abdämpft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007cfae-89a1-4154-9017-f2274dda1d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87aa7f2-dbbd-49b9-b51b-8bb46799f22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b29ce7cf-bb39-4f57-b011-062265d34562",
   "metadata": {},
   "source": [
    "https://martin-grellmann.de/ridge-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315f685-bb70-49d3-9e16-d043ac206b9c",
   "metadata": {},
   "source": [
    "**Ridge Regression** ist eine Technik der linearen Regression, die verwendet wird, um Modelle zu verbessern, wenn Multi-Kollinearität (starke Korrelationen zwischen den unabhängigen Variablen) im Datensatz vorhanden ist oder wenn das Modell überangepasst (Overfitting) ist. Sie fügt der Kostenfunktion einen Regularisierungsterm hinzu, um die Gewichte der Regressionsparameter zu begrenzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d140165-5dc9-486c-993e-247611c7c04a",
   "metadata": {},
   "source": [
    "### Funktionsweise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcb53f-51f1-48b2-abdd-2af6657b368c",
   "metadata": {},
   "source": [
    "Ridge Regression versucht, die Koeffizienten der Regressionsvariablen klein zu halten, indem es eine Strafe für zu große Koeffizienten einführt. Dies hilft, das Modell weniger anfällig für Überanpassung zu machen und verbessert die Generalisierungsfähigkeit auf neuen Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d50939-3cb7-47bd-b41c-233b15c2e2f8",
   "metadata": {},
   "source": [
    "### Ridge Regression Formel:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed2d4-3949-4c68-94c9-89e1cdbd4671",
   "metadata": {},
   "source": [
    "Die Ridge Regression minimiert die folgende Funktion:\n",
    "\n",
    "$$\n",
    "\\text{Kostenfunktion} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93a5f0-1fbc-4f7f-bf0a-eed86f5417fd",
   "metadata": {},
   "source": [
    "### Erklärung der Formel:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125766f4-9cc0-4832-85af-d3b6e7632d0c",
   "metadata": {},
   "source": [
    "- $\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ : Das ist der **Fehlerterm** oder die Summe der quadrierten Abweichungen zwischen den tatsächlichen Werten $y_i$ und den vorhergesagten Werten $\\hat{y}_i$.\n",
    "- $\\sum_{j=1}^{p} \\beta_j^2$ : Der **Regularisierungsterm**, der die Summe der quadrierten Regressionskoeffizienten $\\beta_j$ ist.\n",
    "- $\\lambda$ : Ein **Regularisierungsparameter**, der steuert, wie stark die Bestrafung für große Koeffizienten ist. Je größer $\\lambda$, desto stärker die Bestrafung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04cd892-3a11-4b48-afd0-46bfd343436f",
   "metadata": {},
   "source": [
    "### Wichtige Eigenschaften:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980afa0-29e0-4b6f-9ace-d0cbf3575683",
   "metadata": {},
   "source": [
    "- **Multikollinearität**: Ridge Regression reduziert die Variabilität der Schätzungen, die durch stark korrelierte unabhängige Variablen entsteht.\n",
    "- **Overfitting**: Sie hilft, Overfitting zu verhindern, indem sie die Koeffizienten kleiner macht.\n",
    "- **Bias-Variance Tradeoff**: Ridge Regression erhöht den Bias im Modell, reduziert aber die Varianz, was oft zu besseren Vorhersagen auf neuen Daten führt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724288d-ec1f-4309-a4eb-fd212ffe73f5",
   "metadata": {},
   "source": [
    "### Beispiel:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f0348-e114-40f7-a2f1-e3cd89843fcb",
   "metadata": {},
   "source": [
    "Wenn du ein Modell trainierst, das das Hauspreis auf Basis von 10 Variablen (z.B. Größe, Lage, Zimmeranzahl) vorhersagt und viele dieser Variablen stark korrelieren (z.B. Größe und Zimmeranzahl), dann kann Ridge Regression helfen, stabile Koeffizienten zu schätzen, indem es den Einfluss dieser Variablen dämpft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b48c3e-9a81-42e3-8c44-c4cc8bff0cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
