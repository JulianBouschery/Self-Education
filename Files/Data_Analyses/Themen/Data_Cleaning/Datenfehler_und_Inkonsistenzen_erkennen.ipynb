{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90de8cf8-4ec5-4bab-8b25-06ca66495ccf",
   "metadata": {},
   "source": [
    "https://www.inwt-statistics.de/blog/fehlende-werte-verstehen-und-handhaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddebbba-452b-4bd0-9939-de94d61badcd",
   "metadata": {},
   "source": [
    "# Syllabus\n",
    "\n",
    "Identify data errors and inconsistencies through various diagnostic methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db773356-0348-428b-a67a-98ffad9952e3",
   "metadata": {},
   "source": [
    "# Was sind fehlerhafte Daten?\n",
    "\n",
    "Fehlerhafte Daten umfassen unvollständige, inkonsistente, falsche oder ungenaue Daten, die die Analyse und Entscheidungsfindung verfälschen können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1414a-c313-4e7f-8f19-78fc19b0ebaf",
   "metadata": {},
   "source": [
    "# Typische Datenfehler\n",
    "\n",
    "- Numerische Probleme: Ungültige Werte (z.B. 999 als Platzhalter für fehlende Werte).\n",
    "- Duplikate: Mehrfacheinträge für denselben Datensatz.\n",
    "- Fehlende Werte: Datenspalten oder Felder, die leer sind.\n",
    "- Ungültige Einträge: Daten, die außerhalb des akzeptierten Wertebereichs liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa27b02-4982-43bb-8849-467135bd9837",
   "metadata": {},
   "source": [
    "---\n",
    "# Einfluss fehlerhafter Daten auf Analyseergebnisse\n",
    "\n",
    "Fehlerhafte Daten können zu ernsthaften Problemen führen, darunter Verzerrungen, ungenaue Vorhersagen, falsche Entscheidungen und erheblichem Ressourcenverlust. Um diese Auswirkungen zu minimieren, ist es entscheidend, Daten frühzeitig auf Fehler zu überprüfen, sorgfältige **Datenbereinigung** durchzuführen und Verfahren zur **Qualitätssicherung** zu implementieren.\n",
    "\n",
    "## 1. Verzerrte Analyseergebnisse\n",
    "\n",
    "- fehlerhafte Daten können zu **Bias** (Verzerrung) in den Ergebnissen führen,\n",
    "- bedeutet: die Schätzungen oder Vorhersagen weichen systematisch von den tatsächlichen Werten ab\n",
    "- passiert oft, wenn fehlerhafte Daten nicht zufällig sind und mit bestimmten Merkmalen der Daten zusammenhängen\n",
    "\n",
    "**Beispiel**: <br>\n",
    "Wenn in einer Umfrage die Einkommensdaten reicher Teilnehmer fehlerhaft oder fehlend sind, kann die Analyse ein verzerrtes Bild der Einkommensverteilung geben und zu falschen politischen oder geschäftlichen Entscheidungen führen.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 2. Falsch-positive oder Falsch-negative Ergebnisse\n",
    "- fehlerhafte Daten können die Wahrscheinlichkeit von **falsch-positiven** oder **falsch-negativen** Ergebnissen erhöhen, indem sie falsche Zusammenhänge suggerieren oder echte Zusammenhänge verdecken\n",
    "   \n",
    "**Beispiel**: <br>\n",
    "In einer medizinischen Studie könnten Messfehler zu falschen Schlussfolgerungen über den Effekt eines Medikaments führen, wodurch die tatsächliche Wirksamkeit über- oder unterschätzt wird.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 3. Ungenaue Modelle und Vorhersagen\n",
    "\n",
    "- in Machine-Learning-Modellen können fehlerhafte Daten dazu führen, dass Modelle schlecht generalisieren oder falsche Vorhersagen treffen\n",
    "- wenn z.B. **Outlier**, **Messfehler** oder inkonsistente Daten im Trainingsdatensatz enthalten sind, kann dies dazu führen, dass Modelle die zugrundeliegenden Muster falsch lernen\n",
    "\n",
    "**Beispiel**:<br>\n",
    "Ein Modell, das auf fehlerhaften Verkaufsdaten basiert, könnte schlechte Vorhersagen über die zukünftigen Verkaufszahlen treffen, was wiederum die Planung und Bestandsverwaltung beeinträchtigt.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 4. Geringe Zuverlässigkeit der Ergebnisse\n",
    "\n",
    "- die **Verlässlichkeit** der Ergebnisse werden stark beeinträchtigt\n",
    "- Ergebnisse können angezweifelt oder zurückgewiesen werden, wenn klar wird, dass die zugrunde liegenden Daten fehlerhaft sind\n",
    "\n",
    "**Beispiel**: <br>\n",
    "Wenn bei einem Marketing-Report klar wird, dass Kundeninformationen falsch erfasst wurden (etwa falsche Postleitzahlen oder Geburtsdaten), werden die Schlussfolgerungen über Kundensegmente und Zielmärkte möglicherweise als nicht verlässlich angesehen.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 5. Fehlinterpretationen und falsche Entscheidungen\n",
    "\n",
    "- wenn Entscheidungen auf der Grundlage von fehlerhaften Daten getroffen werden, können sie zu schlechten Ergebnissen führen\n",
    "- besonders kritisch in Geschäfts- oder medizinischen Kontexten, wo Entscheidungen erhebliche Konsequenzen haben können\n",
    "\n",
    "**Beispiel**:<br>\n",
    "Ein Unternehmen könnte aufgrund fehlerhafter Marktforschungsdaten falsche Investitionen tätigen, indem es in Produkte investiert, die in der Realität nicht gefragt sind, oder es könnte profitable Märkte übersehen.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 6. Wissenschaftliche Ungültigkeit\n",
    "\n",
    "- **Reproduzierbarkeit** und **Validität** der Forschungsergebnisse können beeinträchtigt werden\n",
    "- Studien, die auf fehlerhaften Daten basieren, können zu falschen Hypothesen führen und damit das gesamte Forschungsgebiet beeinträchtigen\n",
    "\n",
    "**Beispiel**: <br>\n",
    "Eine Studie zur Wirkung eines neuen Medikaments könnte aufgrund fehlerhafter Erhebungen nicht reproduzierbare Ergebnisse liefern, was Zweifel an den Studienergebnissen und der medizinischen Wirksamkeit weckt.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 7. Kosten und Zeitverschwendung\n",
    "\n",
    "- kann zu erheblichen Kosten und Zeitverlusten führen, da Analysten viel Zeit aufwenden müssen, um die Daten zu bereinigen und die Auswirkungen von Fehlern zu minimieren\n",
    "- \n",
    "**Beispiel**: <br>\n",
    "Ein Unternehmen könnte wertvolle Ressourcen für die Reinigung eines fehlerhaften Datensatzes aufwenden, bevor es ihn verwenden kann. Dies verzögert Projekte und Entscheidungen und kann zu finanziellen Verlusten führen.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 8. Fehlende Vergleichbarkeit\n",
    "\n",
    "- **verschiedene Datensätze nicht mehr vergleichbar**, v.a. wenn es Inkonsistenzen in der Datenerhebung oder -verarbeitung gibt\n",
    "- erschwert es, Ergebnisse zu aggregieren oder Trends über mehrere Datensätze hinweg zu analysieren\n",
    "\n",
    "**Beispiel**: <br>\n",
    "Unterschiedliche Definitionen oder Formate für Zeitangaben (z.B. Datum oder Zeitzone) in einem globalen Datensatz könnten es unmöglich machen, die Ergebnisse zwischen verschiedenen Regionen zu vergleichen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b695896-f5e5-4575-816c-f8227ff6f8dd",
   "metadata": {},
   "source": [
    "---\n",
    "# Methoden zur Erkennung von Datenfehlern\n",
    "\n",
    "\n",
    "- Visuelle Inspektion: <br>\n",
    "  - Identifizieren offensichtlicher Fehler durch das Durchsehen von Daten.\n",
    "  - df['column'].value_counts(): Prüft unplausible Werte in kategorischen Spalten.\n",
    "\n",
    "\n",
    "- Statistische Zusammenfassungen: <br>\n",
    "  - Verwenden von Mittelwerten, Standardabweichungen und Zählungen, um inkonsistente oder abweichende Werte zu erkennen.\n",
    "  - df.describe(): Ermittelt statistische Auffälligkeiten (z.B. Ausreißer).\n",
    "\n",
    "\n",
    "- Fehlende Werte: <br>\n",
    "  - Überprüfung, ob fehlende Werte vorhanden sind.\n",
    "  - df.isnull().sum(): Überprüft auf fehlende Werte.\n",
    "\n",
    "- Duplikate: <br>\n",
    "  - Erkennung und Entfernung mehrfach vorhandener Datensätze.\n",
    "  - df.duplicated(): Findet doppelte Zeilen.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "# Beispiel in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c024841f-fcb0-4649-884b-d09e68cdd2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte:\n",
      "customer_id     0\n",
      "sales_amount    0\n",
      "sales_date      1\n",
      "sort            0\n",
      "dtype: int64\n",
      "\n",
      "Statistische Zusammenfassung:\n",
      "count      5.000000\n",
      "mean     285.800000\n",
      "std      404.812549\n",
      "min      -10.000000\n",
      "25%      120.000000\n",
      "50%      150.000000\n",
      "75%      170.000000\n",
      "max      999.000000\n",
      "Name: sales_amount, dtype: float64\n",
      "\n",
      "Duplikate:\n",
      "   customer_id  sales_amount sales_date   sort\n",
      "2            2           -10       None  short\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sort\n",
       "long     2\n",
       "short    2\n",
       "bird     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Beispieldaten mit Fehlern\n",
    "data = {\n",
    "    'customer_id': [1, 2, 2, 4, 5],\n",
    "    'sales_amount': [120, 150, -10, 999, 170],  # Fehlerhafte Werte\n",
    "    'sales_date': ['2023-01-01', '2023-01-02', None, '2023-01-04', '2023-01-05'],\n",
    "    'sort': ['long', 'short', 'short', 'bird', 'long'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Erkennung fehlender Werte\n",
    "print(\"Fehlende Werte:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Statistische Zusammenfassung, um fehlerhafte numerische Werte zu identifizieren\n",
    "print(\"\\nStatistische Zusammenfassung:\")\n",
    "print(df['sales_amount'].describe())\n",
    "\n",
    "# Erkennung von Duplikaten\n",
    "duplicates = df.duplicated(subset='customer_id')\n",
    "print(\"\\nDuplikate:\")\n",
    "print(df[duplicates])\n",
    "\n",
    "\n",
    "df['sort'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac139a-a2fe-42a4-a2e4-1dc8756df24b",
   "metadata": {},
   "source": [
    "---\n",
    "# Herausforderungen bei manueller Inspektion\n",
    "\n",
    "Die manuelle Inspektion großer Datensätze wird durch die Datenmenge, Komplexität und Anfälligkeit für menschliche Fehler erheblich erschwert. Automatisierte Tools und Algorithmen, die auf maschinellem Lernen oder statistischen Techniken basieren, bieten eine effizientere und genauere Methode, um große Datenmengen zu analysieren und Muster zu erkennen.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Skalierbarkeit\n",
    "   - **Datenmenge:**\n",
    "     - große Datensätze können Millionen oder sogar Milliarden von Zeilen enthalten\n",
    "     - eine manuelle Inspektion dieser Datenmengen ist zeitaufwändig und oft unpraktisch\n",
    "     - selbst einfache Muster zu erkennen, kann schwierig werden<br><br>\n",
    "\n",
    "   - **Komplexität:**\n",
    "     - mit zunehmender Datenmenge wächst häufig auch die Anzahl der Variablen und Verbindungen, was die Analyse noch komplizierter macht\n",
    "\n",
    "<br>\n",
    "\n",
    "## Fehleranfälligkeit\n",
    "   - **Menschliche Fehler:**\n",
    "     - hohes Risiko für Fehler\n",
    "     - Menschen übersehen leicht Anomalien oder Muster<br><br>\n",
    "\n",
    "   - **Inkonsistente Inspektion:**\n",
    "     - Konsistenz der Analyse kann leiden\n",
    "     - Daten können von Menschen unterschiedlich interpretiert werden\n",
    "\n",
    "<br>\n",
    "\n",
    "## Zeit- und Ressourcenaufwand\n",
    "   - **Langsame Verarbeitung:**\n",
    "     - manuelle Überprüfung großer Datenmengen ist extrem zeitaufwändig\n",
    "     - insbesondere wenn jede Beobachtung einzeln betrachtet wird<br><br>\n",
    "\n",
    "   - **Hohe Kosten:**\n",
    "     - Zeitaufwand führt zu hohen Opportunitätskosten\n",
    "     - da die für die Inspektion aufgewendete Zeit für andere, produktivere Aufgaben genutzt werden könnte\n",
    "\n",
    "<br>\n",
    "\n",
    "## Datenvielfalt\n",
    "   - **Unterschiedliche Datenformate:**\n",
    "     - große Datensätze enthalten oft heterogene Datenquellen\n",
    "     - z.B. Text, Zahlen, Bilder\n",
    "     - erfordern jeweils spezielle Analyseansätze\n",
    "     - eine manuelle Inspektion kann Schwierigkeiten haben, alle diese Datentypen effizient zu verarbeiten<br><br>\n",
    "\n",
    "   - **Hohe Dimensionalität:**\n",
    "     - bei vielen Variablen (Dimensionen) wird es schwer, durch manuelle Inspektion sinnvolle Muster oder Zusammenhänge zu erkennen\n",
    "\n",
    "<br>\n",
    "\n",
    "## Erkennung von Mustern\n",
    "   - **Mustererkennung:**\n",
    "     - die manuelle Erkennung von komplexen Mustern oder Ausreißern ist oft ineffizient\n",
    "     - Algorithmen können statistische Abweichungen oder Trends in großen Datensätzen schneller und genauer erkennen als Menschen<br><br>\n",
    "\n",
    "   - **Nicht offensichtliche Korrelationen:**\n",
    "     - oft können Korrelationen oder Zusammenhänge zwischen Variablen nicht durch bloßes Ansehen erkannt werden\n",
    "     - hier sind statistische Modelle oder maschinelle Lernmethoden besser geeignet\n",
    "\n",
    "<br>\n",
    "\n",
    "## Datenqualität und -bereinigung\n",
    "   - **Fehlende oder unvollständige Daten:**\n",
    "     - große Datensätze haben häufig unvollständige, fehlerhafte oder fehlende Einträge\n",
    "     - kann die manuelle Verarbeitung verlangsamen und Fehlerquellen schaffen<br><br>\n",
    "   \n",
    "   - **Duplikate und Inkonsistenzen:**\n",
    "     - Duplikate oder Inkonsistenzen können schwer zu identifizieren sein, v.a. in großen Datenmengen\n",
    "\n",
    "<br>\n",
    "\n",
    "## Subjektivität\n",
    "   - **Unterschiedliche Interpretationen:**\n",
    "     - manuelle Inspektion kann subjektiv sein\n",
    "     - kann zu inkonsistenten Ergebnissen führen\n",
    "     - v.a. wenn mehrere Personen beteiligt sind<br><br>\n",
    "   \n",
    "   - **Bias:**\n",
    "     - Vorannahmen der Analysten können dazu führen, dass bestimmte Muster übersehen oder Ergebnisse falsch interpretiert werden\n",
    "\n",
    "<br>\n",
    "\n",
    "## Limitierte Visualisierung\n",
    "   - **Eingeschränkte Visualisierungsfähigkeiten:**\n",
    "     - ohne Unterstützung automatisierter Visualisierungstechniken ist es schwierig, große Datensätze manuell in einer verständlichen Form darzustellen\n",
    "     - Werkzeuge wie Matplotlib oder Seaborn können helfen, aber benötigen eine gewisse Vorbereitung und automatisierte Prozesse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8dd08-0741-4fab-89ee-271251017082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
