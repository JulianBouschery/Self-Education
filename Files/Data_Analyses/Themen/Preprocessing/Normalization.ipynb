{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355a06cd-dcd2-4288-a926-0d797a9e815b",
   "metadata": {},
   "source": [
    "Siehe auch: [Unterscheid zwischen Skalierung und Normalisierung](Normalization_vs._Scaling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1ee87-a41c-4485-9e08-89297736a778",
   "metadata": {},
   "source": [
    "# Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd23fe-3671-4bb9-a199-23db596b407b",
   "metadata": {},
   "source": [
    "https://www.mql5.com/de/articles/11200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc0276-76d8-4ccc-b8ee-9717011b8231",
   "metadata": {},
   "source": [
    "https://de.wikipedia.org/wiki/Paraboloid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee1ce5-9a41-4e65-ad49-4881d2b906d9",
   "metadata": {},
   "source": [
    "Minimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249623ab-e7f8-4034-8dcd-6671d225b2ce",
   "metadata": {},
   "source": [
    "https://databasecamp.de/ki/gradientenverfahren-ein-steiler-abstieg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c74723-9f42-41cf-9a78-5916b12600b3",
   "metadata": {},
   "source": [
    "### 2. **Normalisierung (Normalization)**:\n",
    "- Normalisierung bezieht sich auf das **Anpassen der Daten auf eine spezifische Verteilung**, oft um die Daten einer bestimmten Struktur anzupassen, wie z.B. die Länge eines Vektors.\n",
    "- Häufig wird dies verwendet, um die Länge eines Vektors auf 1 zu normieren (oft bei Machine Learning-Modellen).\n",
    "- Normalisierung wird oft im Zusammenhang mit **Zeitreihendaten** oder bei **Vektoren** verwendet.\n",
    "- **Beispiel:**\n",
    "  - **L2-Normalisierung**: Normiert den Vektor so, dass die Summe der quadrierten Werte gleich 1 ist (Vektorlänge = 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc86548-bd0e-40e3-bb30-8a22b7160e56",
   "metadata": {},
   "source": [
    "### 2. **Normalisierung (Normalization)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213dc99-2d3d-4cf1-9344-c92068b3a7fc",
   "metadata": {},
   "source": [
    "- **Ziel**: Normalisierung wird verwendet um Daten in eine spezifische Form zu bringen, oder sie einer bestimmten Struktur anzupassen, wie z.B. die Länge eines Vektors, oft mit einer festen Skalenlänge oder Verteilung. Dies ist wichtig, um die Vergleichbarkeit und Stabilität der Daten zu verbessern, insbesondere bei Vektoren oder Zeitreihendaten.\n",
    "- **Häufig verwendet bei Vektoren**: Normalisierung wird verwendet, um die Länge eines Vektors zu skalieren, ohne die Richtung zu verändern. Eine gängige Form ist die L2-Normalisierung, bei der die Summe der quadrierten Werte gleich 1 wird, also die Vektorlänge auf 1 skaliert wird.\n",
    "- **Anwendungsbeispiele**:\n",
    "  - **Maschinelles Lernen**: Bei der Arbeit mit Modellen wie K-Nearest Neighbors ist es wichtig, dass alle Vektoren die gleiche Länge haben, um die Vergleichbarkeit von Datenpunkten zu gewährleisten.\n",
    "  - **Zeitreihen und Signalverarbeitung**: Bei der Analyse von Zeitreihen kann Normalisierung dazu beitragen, dass Variationen unabhängig von der absoluten Skala erkannt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee602ad-d29a-42b1-8f84-a714da874944",
   "metadata": {},
   "source": [
    "- **Ziel**: Die Normalisierung dient dazu, Daten in eine spezifische Form zu bringen oder sie einer bestimmten Struktur anzupassen, wie beispielsweise der Länge eines Vektors. Dies geschieht häufig mit einer festen Skalenlänge oder Verteilung, was die Vergleichbarkeit und Stabilität der Daten verbessert, insbesondere bei Vektoren oder Zeitreihendaten.\n",
    "  \n",
    "- **Einsatz bei Vektoren**: Normalisierung wird genutzt, um die Länge eines Vektors zu skalieren, ohne dessen Richtung zu verändern. Eine häufige Methode ist die L2-Normalisierung, bei der die Summe der quadrierten Werte auf 1 normiert wird, wodurch die Vektorlänge auf 1 skaliert wird.\n",
    "\n",
    "- **Anwendungsbeispiele**:\n",
    "  - **Maschinelles Lernen**: In Modellen wie K-Nearest Neighbors ist es entscheidend, dass alle Vektoren dieselbe Länge haben, um die Vergleichbarkeit der Datenpunkte sicherzustellen.\n",
    "  - **Zeitreihen und Signalverarbeitung**: Bei der Analyse von Zeitreihen ermöglicht die Normalisierung, dass Variationen unabhängig von der absoluten Skala erkannt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cfff0-b308-4e0b-81c2-0129dea99d23",
   "metadata": {},
   "source": [
    "### **Beispiel in Python mit L2-Normalisierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6337132b-1f42-4ffc-8308-0f95c967c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originaler Vektor: [[25000 50000 75000]]\n",
      "L2-normalisierter Vektor: [[0.26726124 0.53452248 0.80178373]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Beispieldaten: Ein Vektor mit Einkommensdaten in Tausendern\n",
    "vektor = np.array([[25000, 50000, 75000]])\n",
    "\n",
    "# L2-Normalisierung\n",
    "l2_normalisiert = normalize(vektor, norm='l2')\n",
    "\n",
    "print(\"Originaler Vektor:\", vektor)\n",
    "print(\"L2-normalisierter Vektor:\", l2_normalisiert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8cd17a-06da-4c81-a7e5-608cc35223cf",
   "metadata": {},
   "source": [
    "In diesem Beispiel:\n",
    "- Der originale Vektor hat eine große Spannweite der Werte.\n",
    "- Der L2-normalisierte Vektor hat eine Länge (also eine Summe der quadrierten Werte) von 1. So werden die relativen Unterschiede beibehalten, während die absolute Größe angepasst ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d632f60-594d-4d73-8051-ef831b6f957a",
   "metadata": {},
   "source": [
    "In der Statistik wird Normalisierung verwendet, um Daten zu transformieren, sodass sie sich besser miteinander vergleichen lassen und Analysen weniger verzerrt sind. \n",
    "\n",
    "### Ziele der Normalisierung in der Statistik:\n",
    "1. **Datenvergleichbarkeit herstellen**: Werte, die ursprünglich auf verschiedenen Skalen oder in unterschiedlichen Größenordnungen vorliegen, werden vergleichbar gemacht.\n",
    "2. **Analyse stabilisieren**: Durch Normalisierung können Verzerrungen in den Daten minimiert werden, wodurch statistische Methoden robuster und zuverlässiger werden.\n",
    "3. **Verteilungsannahmen erfüllen**: Viele statistische Tests setzen eine bestimmte Verteilung (oft Normalverteilung) voraus. Normalisierung kann Daten dieser Verteilung anpassen.\n",
    "\n",
    "### Häufige Methoden der Normalisierung in der Statistik:\n",
    "\n",
    "1. **Min-Max-Normalisierung**: \n",
    "   - Skaliert die Werte in einen festen Bereich, meistens [0, 1].\n",
    "   - Formel:\n",
    "     \\[\n",
    "     X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "     \\]\n",
    "   - **Anwendungsfall**: Ideal für Daten, bei denen ein fester Wertebereich gewünscht ist, z. B. in visuellen Darstellungen.\n",
    "\n",
    "2. **Z-Score-Normalisierung (Standardisierung)**:\n",
    "   - Transformiert die Daten so, dass der Mittelwert bei 0 und die Standardabweichung bei 1 liegt.\n",
    "   - Formel:\n",
    "     \\[\n",
    "     X_{\\text{norm}} = \\frac{X - \\mu}{\\sigma}\n",
    "     \\]\n",
    "   - **Anwendungsfall**: Besonders nützlich, wenn Daten auf ihre relative Abweichung zum Mittelwert untersucht werden sollen. Diese Methode ist geeignet, wenn Variablen in Analysen wie der linearen Regression oder beim maschinellen Lernen verwendet werden, da sie die Verteilung der Daten berücksichtigt.\n",
    "\n",
    "3. **Logarithmische Transformation**:\n",
    "   - Verwendet einen Logarithmus, um sehr große Werte zu reduzieren und die Verteilung zu stabilisieren.\n",
    "   - Formel (natürlicher Logarithmus): \n",
    "     \\[\n",
    "     X_{\\text{log}} = \\ln(X)\n",
    "     \\]\n",
    "   - **Anwendungsfall**: Besonders geeignet, wenn Daten rechtsschief verteilt sind, wie bei Einkommens- oder Populationsgrößen. Dadurch werden extreme Werte weniger dominant, was die Analyse und die Visualisierung erleichtert.\n",
    "\n",
    "### Beispiel in Python (Z-Score-Normalisierung):\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Beispieldaten\n",
    "data = {'Einkommen': [25000, 50000, 75000, 100000, 125000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Z-Score Normalisierung\n",
    "scaler = StandardScaler()\n",
    "df['Einkommen_normalisiert'] = scaler.fit_transform(df[['Einkommen']])\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "In diesem Beispiel:\n",
    "- `Einkommen_normalisiert` zeigt die Einkommenswerte auf einer standardisierten Skala. Das macht sie vergleichbar, selbst wenn die ursprünglichen Werte stark unterschiedlich sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211f2ef-9cfd-430c-9936-e9af59f4fdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
