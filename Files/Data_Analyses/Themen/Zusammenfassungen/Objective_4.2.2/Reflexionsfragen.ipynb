{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9ab7ae-9d3c-4352-a1f5-565ffbc330e3",
   "metadata": {},
   "source": [
    "## Reflexionsfragen:\n",
    "1. Warum ist es wichtig, einen separaten Testdatensatz zu verwenden?\n",
    "2. Was könnte passieren, wenn Sie denselben Datensatz sowohl für das Training als auch für das Testen verwenden?\n",
    "3. Wie könnten Sie die Testgenauigkeit Ihres Modells weiter verbessern?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cede3-3160-43ec-b4bc-b156dba2015e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Lösungen\n",
    "\n",
    "1. Warum ist es wichtig, einen separaten Testdatensatz zu verwenden?\n",
    "- **Antwort**: Ein separater Testdatensatz ist wichtig, um die Generalisierungsfähigkeit eines Modells zu überprüfen. Der Testdatensatz enthält Daten, die das Modell während des Trainings nicht gesehen hat. Dies hilft, eine unvoreingenommene Bewertung der Modellleistung auf neuen Daten vorzunehmen. Ohne einen separaten Testdatensatz könnten wir nicht sicher sein, ob das Modell wirklich Muster in den Daten gelernt hat oder nur die Trainingsdaten \"auswendig\" gelernt hat.\n",
    "\n",
    "2. Was könnte passieren, wenn Sie denselben Datensatz sowohl für das Training als auch für das Testen verwenden?\n",
    "- **Antwort**: Wenn derselbe Datensatz sowohl für das Training als auch für das Testen verwendet wird, kann das Modell die Daten möglicherweise \"auswendig\" lernen (Overfitting). Dies bedeutet, dass das Modell auf den Trainingsdaten eine sehr hohe Leistung erzielt, aber auf neuen, unvorhergesehenen Daten nicht gut funktioniert. Dadurch wird die Testgenauigkeit künstlich hoch und reflektiert nicht die tatsächliche Leistungsfähigkeit des Modells.\n",
    "\n",
    "3. Wie könnten Sie die Testgenauigkeit Ihres Modells weiter verbessern?\n",
    "- **Antwort**: Um die Testgenauigkeit zu verbessern, können verschiedene Methoden angewendet werden:\n",
    "    1. **Feature Engineering**: Zusätzliche relevante Merkmale (Features) extrahieren oder existierende Features transformieren, um das Modell besser mit Informationen zu versorgen.\n",
    "    2. **Hyperparameter-Tuning**: Die optimalen Hyperparameter des Modells durch Techniken wie Grid Search oder Random Search finden.\n",
    "    3. **Regularisierung**: Überanpassung durch Techniken wie Lasso- oder Ridge-Regression verhindern.\n",
    "    4. **Mehr Trainingsdaten sammeln**: Ein größeres Trainingsset kann helfen, das Modell robuster zu machen.\n",
    "    5. **Ensemble-Methoden**: Mehrere Modelle kombinieren (z.B. Bagging, Boosting), um die Vorhersagegenauigkeit zu verbessern.\n",
    "    6. **Cross-Validation**: Verwenden von Cross-Validation-Techniken, um das Modell auf stabilere Weise zu validieren und zu optimieren.\n",
    "\n",
    "Diese Maßnahmen können dazu beitragen, die Modellleistung auf neuen Daten zu verbessern und das Risiko von Overfitting zu reduzieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01c66c-cbbb-470e-a51f-759128e92ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
