{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d960ff-d86d-4d5a-943f-b43b11df9cfb",
   "metadata": {},
   "source": [
    "Daten-Normalisierung bringt **numerische Variablen** auf eine ähnliche Skala, was wichtig ist, wenn Modelle, wie z.B. maschinelles Lernen, von der Skala der Daten beeinflusst werden\n",
    "\n",
    "https://medium.com/@weidagang/demystifying-machine-learning-normalization-0cdb8b281234\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1592e2-f45a-4b46-842d-ba2d98b2eea9",
   "metadata": {},
   "source": [
    "# Syllabus\n",
    "\n",
    "Understand the necessity of data normalization to bring different variables onto a similar scale for comparative analysis.\n",
    "\n",
    "Understand various scaling methods like Min-Max scaling and Z-score normalization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a51f5-594e-4c2c-8694-f5fd6827597e",
   "metadata": {},
   "source": [
    "# Was ist Normalisierung bzw. Standardisierung?\n",
    "\n",
    "- **Normalisierung** bedeutet im Allgemeinen, Daten so zu transformieren, dass sie in einem bestimmten Bereich oder einer bestimmten Skala liegen\n",
    "- oft um unterschiedliche Messgrößen vergleichbar zu machen oder\n",
    "- um bessere Ergebnisse in maschinellen Lernalgorithmen zu erzielen\n",
    "- bezieht sich häufig auf das Umwandeln von numerischen Daten auf eine Skala, z.B. zwischen 0 und 1 oder so, dass der Mittelwert 0 und die Standardabweichung 1 beträgt (auch **Standardisierung** genannt).\n",
    "- **Skalierung** (Standardisierung) bringt Daten auf eine Standard-Normalverteilung (Mittelwert 0, Standardabweichung 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0df8d-35e1-4eee-a2b2-204ebcf157da",
   "metadata": {},
   "source": [
    "# Warum normalisieren und skalieren?\n",
    "\n",
    "- Gleichmäßige Verarbeitung\n",
    "  - viele Algorithmen basieren auf Abständen zwischen Datenpunkten\n",
    "  - z.B. k-nearest neighbors, SVMs\n",
    "  - unterschiedliche Skalen der Features führen zu Verzerrungen\n",
    "- Schnellere Konvergenz\n",
    "- Reduktion von Verzerrungen\n",
    "  - Features mit größeren Werten können den Einfluss dominieren, wenn sie nicht skaliert werden\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3577b17-f41d-4a0a-a274-2c2f936515a9",
   "metadata": {},
   "source": [
    "# Normalisierungsmethoden\n",
    "\n",
    "## Min-Max-Normalisierung\n",
    "   - Werte werden so transformiert, dass sie innerhalb eines Bereichs liegen\n",
    "   - typischerweise 0 bis 1\n",
    "   - gut geeignet, wenn die Daten keine Ausreißer haben und eine Begrenzung auf einen festen Bereich gewünscht ist\n",
    "   - wird bevorzugt, wenn die Daten in einem festen Bereich liegen sollen\n",
    "   - empfindlich gegenüber Ausreißern, da sie extreme Werte in die Berechnung einbezieht\n",
    "\n",
    "\n",
    "<br>\n",
    "   \n",
    "$\n",
    " X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c51d17-750d-4b1e-83a2-1cbe3b7422b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max normalisierte Daten:\n",
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [1.         1.        ]\n",
      " [0.66666667 0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Beispiel-Daten\n",
    "data = np.array([[1, 2], [2, 3], [4, 5], [3, 4]])\n",
    "\n",
    "# Min-Max-Skalierung auf den Bereich 0-1 anwenden\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Min-Max normalisierte Daten:\")\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869153ea-f9c5-482b-81f6-3f47af677bbb",
   "metadata": {},
   "source": [
    "## Z-Score-Normalisierung\n",
    "   - sorgt dafür, dass die Daten einen Mittelwert von 0 und eine Standardabweichung von 1 haben\n",
    "   - robuster gegenüber Ausreißern, da sie den Mittelwert und die Standardabweichung verwendet\n",
    "  \n",
    "     $\n",
    "     Z = \\frac{X - \\mu}{\\sigma}\n",
    "     $\n",
    "\n",
    "\n",
    "   My der Mittelwert und Sigma die Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d78e1c-ded5-429c-8d62-661f3ecc2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score normalisierte Daten:\n",
      "[[-1.34164079 -1.34164079]\n",
      " [-0.4472136  -0.4472136 ]\n",
      " [ 1.34164079  1.34164079]\n",
      " [ 0.4472136   0.4472136 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Beispiel-Daten\n",
    "data = np.array([[1, 2], [2, 3], [4, 5], [3, 4]])\n",
    "\n",
    "# Z-Score-Normalisierung\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Z-Score normalisierte Daten:\")\n",
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319f834-f391-482c-ba21-dbc5459ed60b",
   "metadata": {},
   "source": [
    "## Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7597f717-53fe-4591-870e-7ce4bb97e5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daten nach der Min-Max-Skalierung und Z-Score-Normalisierung:\n",
      "   age  income  age_scaled  income_scaled  age_zscore  income_zscore\n",
      "0   25   50000        0.00       0.000000   -1.414214      -1.249390\n",
      "1   30   60000        0.25       0.142857   -0.707107      -0.858956\n",
      "2   35   80000        0.50       0.428571    0.000000      -0.078087\n",
      "3   40  100000        0.75       0.714286    0.707107       0.702782\n",
      "4   45  120000        1.00       1.000000    1.414214       1.483651\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Beispieldaten\n",
    "data = {'age': [25, 30, 35, 40, 45],\n",
    "        'income': [50000, 60000, 80000, 100000, 120000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Min-Max-Skalierung\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df[['age_scaled', 'income_scaled']] = min_max_scaler.fit_transform(df[['age', 'income']])\n",
    "\n",
    "# Z-Score-Normalisierung\n",
    "z_scaler = StandardScaler()\n",
    "df[['age_zscore', 'income_zscore']] = z_scaler.fit_transform(df[['age', 'income']])\n",
    "\n",
    "print(\"\\nDaten nach der Min-Max-Skalierung und Z-Score-Normalisierung:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6690a1-08c4-4ffb-92ab-cdebae8c80ec",
   "metadata": {},
   "source": [
    "# Wann ist Normalisierung notwendig?\n",
    "\n",
    "- bei Daten mit unterschiedlicher Größenordnung\n",
    "  - z.B. Alter im Bereich 20-60, Einkommen im Bereich 30.000-100.000...\n",
    "- wenn Algorithmen wie k-nearest neighbors (k-NN), logistische Regression oder neuronale Netze verwendet werden\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c76526-97f3-4628-96df-7824578bb8c0",
   "metadata": {},
   "source": [
    "# Einfluss auf das Machine Learning\n",
    "\n",
    "- **Skalierung der Daten** beeinflusst Leistung von maschinellen Lernmodellen erheblich\n",
    "- v.a. in Algorithmen, die auf Distanzen oder Gewichten basieren\n",
    "\n",
    "<br>\n",
    "\n",
    "**1. Verbesserte Genauigkeit bei distanzbasierten Algorithmen** \n",
    "- Algorithmen wie **K-Nearest Neighbors (KNN)**, **Support Vector Machines (SVM)** und **k-Means** verwenden Distanzen zwischen den Datenpunkten. \n",
    "- ohne Skalierung könnten Merkmale mit großen Werten den Abstand dominieren und die kleineren Merkmale \"überstimmen\", obwohl sie genauso wichtig sein könnten\n",
    "\n",
    "- **Ohne Skalierung**: Merkmale mit größeren Werten beeinflussen den Algorithmus mehr, was zu verzerrten Ergebnissen führt\n",
    "- **Mit Skalierung**: Alle Merkmale haben den gleichen Einfluss, was zu einer besseren Modellleistung führt.\n",
    "<br>\n",
    "\n",
    "**Beispiel:**\n",
    "Ein Datensatz enthält zwei Merkmale: Alter (0–100) und Einkommen (0–100,000). <br>\n",
    "Ohne Skalierung würde das Einkommen das Alter dominieren, was den Algorithmus in die falsche Richtung lenken könnte.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Schnellere und stabilere Konvergenz bei gradientenbasierten Algorithmen**\n",
    "- Algorithmen mit **Gradientenabstieg** verwenden profitieren stark von der Skalierung\n",
    "- z.B. **lineare Regression**, **logistische Regression** oder **neuronale Netze**\n",
    "- bei nicht skalierten Daten kann der Gradientenabstieg ineffizient und langsam konvergieren, da die Schrittweiten für Merkmale unterschiedlicher Skalen stark variieren\n",
    "\n",
    "- **Ohne Skalierung**: Der Gradientenabstieg macht für Merkmale mit größeren Werten größere Schritte, was zu einer langsamen oder unstabilen Konvergenz führt.\n",
    "- **Mit Skalierung**: Die Schritte des Gradientenabstiegs sind gleichmäßig über alle Merkmale, was zu einer schnelleren und stabileren Konvergenz führt.\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Verbesserte Modellinterpretation**\n",
    "- in einigen Algorithmen geben die Koeffizienten die relative Bedeutung der Merkmale an\n",
    "\n",
    "- nicht-skalierte Daten können die Interpretation der Bedeutung der Koeffizienten erschweren, da sie von der Skala der Variablen abhängen\n",
    "\n",
    "- **Ohne Skalierung**: Die Koeffizienten können irreführend oder schwer zu interpretieren sein.\n",
    "- **Mit Skalierung**: Die Koeffizienten zeigen den tatsächlichen Einfluss jedes Merkmals, unabhängig von dessen ursprünglicher Skala.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Wann ist Skalierung nicht so entscheidend?\n",
    "- bei Modellen wie **Baum-basierten Algorithmen** (z.B. **Entscheidungsbäume**, **Random Forests**) i.d.R. nicht erforderlich\n",
    "- diese Modelle sind von Splits auf den Merkmalen abhängig sind und nicht von Distanzen oder Koeffizienten\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2efd4d-9fb8-42f9-96ca-9762273f8ffe",
   "metadata": {},
   "source": [
    "# Welche Probleme können auftreten, wenn Variablen in verschiedenen Maßstäben vorliegen?\n",
    "\n",
    "\n",
    "1. **Dominanz großer Skalen**: <br>\n",
    "Variablen mit größeren Werten dominieren das Modell und überlagern kleinere, auch wenn diese wichtig sind.\n",
    "   \n",
    "2. **Verzerrte Distanzberechnungen**: <br>\n",
    "Bei distanzbasierten Algorithmen wie KNN beeinflussen Variablen mit größeren Werten die Distanzen unverhältnismäßig stark.\n",
    "\n",
    "3. **Langsame Konvergenz**: <br>\n",
    "Gradientbasierte Algorithmen (z.B. lineare Regression) konvergieren langsamer oder instabil, wenn die Variablen unterschiedlich skaliert sind.\n",
    "\n",
    "4. **Schwer vergleichbare Koeffizienten**: <br>\n",
    "In Regressionsmodellen sind die Koeffizienten bei unterschiedlichen Skalen der Variablen nicht direkt vergleichbar.\n",
    "\n",
    "5. **Falsche Regularisierung**: <br>\n",
    "Regularisierungsverfahren wie Lasso oder Ridge behandeln unterschiedlich skalierte Variablen ungleich.\n",
    "\n",
    "Daten sollten skaliert werden, um diese Verzerrungen zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474efc9a-0135-4d75-baf7-11425da95eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
