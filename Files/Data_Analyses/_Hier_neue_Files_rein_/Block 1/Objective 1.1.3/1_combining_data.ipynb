{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a791bcbe-1bdc-4fd7-a02c-67227a2a5427",
   "metadata": {},
   "source": [
    "# Syllabus\n",
    "\n",
    "Explain techniques for combining data from various sources, such as databases, APIs, and file-based storage.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4bfc7-9df6-413f-9784-7f45976de009",
   "metadata": {},
   "source": [
    "# Was bedeutet Datenaggregation?\n",
    "\n",
    "- Datenaggregation ist der Prozess, bei dem Daten aus mehreren Quellen zusammengeführt werden, um einen umfassenden Datensatz zu erstellen.\n",
    "- Typische Quellen umfassen:\n",
    "    - **Datenbanken:** <br>\n",
    "    Strukturierte Daten aus relationalen oder NoSQL-Datenbanken.\n",
    "    - **APIs:** <br>\n",
    "    Daten von externen Services oder Plattformen.\n",
    "    - **Dateibasierte Speicherung:** <br>\n",
    "    Daten in Dateien wie CSV, Excel oder JSON.\n",
    "\n",
    "**Beispiel:**\n",
    "Ein Unternehmen sammelt Daten aus internen Verkaufsdatenbanken, kombiniert sie mit Kundendaten aus einer externen CRM-API und fügt zusätzliche Marktanalysen hinzu, die in CSV-Dateien vorliegen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cf3d1-a074-4bc6-9db5-1e839616233e",
   "metadata": {},
   "source": [
    "# Ablauf Datenkombination aus verschiedenen Quwllwn\n",
    "\n",
    "Um Daten aus verschiedenen Quellen zu kombinieren, gibt es eine Reihe von Techniken und Werkzeugen, die je nach Anwendungsfall und Datenquelle zum Einsatz kommen:\n",
    "\n",
    "1. **Datenextraktion**\n",
    "   - **Datenbanken**: <br>\n",
    "     - über SQL-Abfragen aus relationalen Datenbanken\n",
    "     - durch Tools wie **Pandas** können SQL-Abfragen direkt ausgeführt und die Ergebnisse in DataFrames geladen werden\n",
    "   - **APIs**: <br>\n",
    "     - eine HTTP-basierte Schnittstelle verwendet\n",
    "     - Daten mit Tools wie **requests** können darüber abgerufen werden\n",
    "     - die Daten liegen oft im JSON- oder XML-Format vor\n",
    "   - **Dateibasierte Speicher**: <br>\n",
    "     - Daten aus CSV-, Excel-, JSON- oder anderen dateibasierten Formaten\n",
    "     - können mit Bibliotheken wie **Pandas** für CSV/Excel oder **json** für JSON-Dateien gelesen werden\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **Datenvorbereitung** <br>\n",
    "\n",
    "   Sobald die Daten extrahiert sind, müssen sie für die Kombination vorbereitet werden. Dazu gehören:\n",
    "   - **Datentypen prüfen**: <br>\n",
    "   Sicherstellen, dass die relevanten Spalten gleiche oder kompatible Datentypen haben (z. B. Datum, Text, numerisch).\n",
    "   - **Fehlende Werte behandeln**: <br>\n",
    "   Umgang mit fehlenden Werten, entweder durch Auffüllen (Imputation), Löschen oder andere Techniken.\n",
    "   - **Duplikate entfernen**: <br>\n",
    "   Falls Daten mehrfach extrahiert wurden, sollten Duplikate entfernt werden.\n",
    "\n",
    "<br>\n",
    "\n",
    "3. **Datenzusammenführung** <br>\n",
    "\n",
    "   Es gibt mehrere Ansätze, um Daten zu kombinieren, abhängig von der Struktur und den Beziehungen zwischen den Datensätzen:\n",
    "   \n",
    "   - **Joins**: <br>\n",
    "   Daten können ähnlich wie in SQL-Tabellen durch **inner**, **outer**, **left** oder **right joins** zusammengeführt werden. In Python geschieht dies z. B. mit Pandas durch die Funktion `merge()`.\n",
    "     - **Inner Join**: <br>\n",
    "     Nur gemeinsame Daten in beiden Datensätzen werden kombiniert.\n",
    "     - **Left/Right Join**: <br>\n",
    "     Alle Daten aus einem Datensatz werden behalten, auch wenn es keine Übereinstimmung im anderen gibt.\n",
    "     - **Outer Join**: <br>\n",
    "     Alle Daten aus beiden Quellen werden kombiniert, auch wenn es keine Übereinstimmungen gibt.\n",
    "   \n",
    "   - **Concatenation**: <br>\n",
    "   Daten können auch einfach untereinandergehängt (vertikal) oder nebeneinander (horizontal) kombiniert werden, falls sie eine ähnliche Struktur aufweisen. Mit **Pandas** lässt sich dies durch die Funktion `concat()` umsetzen.\n",
    "   \n",
    "   - **Mapping**: <br>\n",
    "   Daten aus verschiedenen Quellen können basierend auf einer gemeinsamen Schlüsselspalte gemappt werden, um neue Informationen anzureichern (z. B. Daten aus einer API zu bestehenden Daten in einer Datenbank hinzufügen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b1aa9d-68d0-46df-b127-52f49fc2781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name  score\n",
      "0   2      Bob     85\n",
      "1   3  Charlie     90\n"
     ]
    }
   ],
   "source": [
    "# Beispiel Inner Join\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Datenquellen\n",
    "df1 = pd.DataFrame({'id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'id': [2, 3, 4], 'score': [85, 90, 88]})\n",
    "\n",
    "# Inner Join\n",
    "df_combined = pd.merge(df1, df2, on='id', how='inner')\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed0f4f9-a7b5-4359-a712-abdee58a348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel Konkatenation\n",
    "\n",
    "# Vertikale Konkatenation\n",
    "df_combined = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Horizontale Konkatenation\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d83af1-6ddd-473c-835d-0840d9fdc342",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "4. **Transformation** <br>\n",
    "\n",
    "   Nach der Zusammenführung müssen die Daten möglicherweise transformiert werden, um für die Analyse nutzbar zu sein:\n",
    "   - **Normalisierung**: <br>\n",
    "   Daten, die in unterschiedlichen Formaten (z. B. Währungen, Zeitzonen) vorliegen, müssen in ein einheitliches Format umgewandelt werden.\n",
    "   - **Aggregation**: <br>\n",
    "   Daten, die auf einer granularen Ebene vorliegen, können aggregiert werden, um aussagekräftige Kennzahlen zu erhalten.\n",
    "   - **Feature Engineering**: <br>\n",
    "   Neue Merkmale können aus bestehenden Daten abgeleitet werden, z. B. das Berechnen von Durchschnittswerten oder das Erstellen von Kategorien.\n",
    "\n",
    "<br>\n",
    "\n",
    "  **Werkzeuge für die Integration**\n",
    "   - **ETL-Tools (Extract, Transform, Load)**: <br>\n",
    "   Tools wie **Apache Nifi**, **Talend** oder **Airflow** helfen bei der Automatisierung von Datenextraktions-, Transformations- und Ladeprozessen.\n",
    "   - **Datenpipelines**: <br>\n",
    "   Automatisierte Workflows, die verschiedene Datenquellen periodisch abrufen, verarbeiten und integrieren, um eine fortlaufende Datenintegration zu ermöglichen.\n",
    "   - **API-Orchestrierung**: <br>\n",
    "   Tools wie **GraphQL** können verwendet werden, um Daten aus mehreren APIs zu kombinieren und die Anfragen zu optimieren.\n",
    "\n",
    "<br>\n",
    "\n",
    "  **Herausforderungen**\n",
    "   - **Dateninkonsistenzen**: <br>\n",
    "   Unterschiedliche Datenformate und Standards zwischen den Quellen.\n",
    "   - **Datenvolumen**: <br>\n",
    "   Große Datenmengen aus verschiedenen Quellen zu verarbeiten, erfordert effiziente Speicher- und Verarbeitungsstrategien.\n",
    "   - **API-Limits**: <br>\n",
    "   Bei der Arbeit mit APIs können Begrenzungen in Bezug auf die Anzahl der Anfragen pro Zeiteinheit bestehen.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f4014-8fa8-4e8b-9ee2-ab112d90f1db",
   "metadata": {},
   "source": [
    "# Quellenarten\n",
    "\n",
    "## Datenbanken\n",
    "\n",
    "- Datenbanken (z.B. MySQL, PostgreSQL, MongoDB) speichern strukturierte Daten, die für Analysen genutzt werden können.\n",
    "- **Beispiel**<br>\n",
    "  Erstellen der Datenbank, SQL-Abfrage und Daten anzeigen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8950eb54-a937-4d47-8d4e-eda56a52a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id    product  sales_amount  sales_date\n",
      "0            1  Product_A         120.0  2023-01-01\n",
      "1            2  Product_B         150.0  2023-01-02\n",
      "2            3  Product_C         130.0  2023-01-03\n",
      "3            4  Product_D         170.0  2023-01-04\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Verbindung zur Datenbank herstellen (wenn sie nicht existiert, wird sie erstellt)\n",
    "conn = sqlite3.connect('sales.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Tabelle sales_data erstellen\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS sales_data (\n",
    "    customer_id INTEGER,\n",
    "    product TEXT,\n",
    "    sales_amount REAL,\n",
    "    sales_date TEXT\n",
    ")\n",
    "'''\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Beispiel-Daten einfügen\n",
    "sales_data = [\n",
    "    (1, 'Product_A', 120.0, '2023-01-01'),\n",
    "    (2, 'Product_B', 150.0, '2023-01-02'),\n",
    "    (3, 'Product_C', 130.0, '2023-01-03'),\n",
    "    (4, 'Product_D', 170.0, '2023-01-04')\n",
    "]\n",
    "\n",
    "insert_query = 'INSERT INTO sales_data (customer_id, product, sales_amount, sales_date) VALUES (?, ?, ?, ?)'\n",
    "cursor.executemany(insert_query, sales_data)\n",
    "\n",
    "# Änderungen speichern\n",
    "conn.commit()\n",
    "\n",
    "# Daten abfragen und anzeigen\n",
    "query = \"SELECT * FROM sales_data\"\n",
    "sales_data_df = pd.read_sql(query, conn)\n",
    "print(sales_data_df)\n",
    "\n",
    "# Verbindung schließen\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f3860-9897-4f74-82de-11f5ce358986",
   "metadata": {},
   "source": [
    "## APIs\n",
    "\n",
    "= Application Programming Interfaces\n",
    "\n",
    "APIs ermöglichen den Zugriff auf Daten von Drittanbietern oder internen Systemen.\n",
    "\n",
    "Beispiele für APIs:\n",
    "- https://jsonplaceholder.typicode.com/\n",
    "\n",
    "- https://openweathermap.org/api   zahlungspflichtig!\n",
    "\n",
    "- https://api.coingecko.com/api/v3/\n",
    "\n",
    "\n",
    "Beispiele in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6b032-5705-4161-9e17-4930da604556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Daten von der Random User API abrufen\n",
    "response = requests.get('https://randomuser.me/api/?results=10')\n",
    "\n",
    "# Überprüfen, ob die Anfrage erfolgreich war\n",
    "if response.status_code == 200:\n",
    "    api_data = response.json()  # Die API gibt JSON-Daten zurück\n",
    "    customers_data = pd.DataFrame(api_data['results'])  # In einen DataFrame umwandeln\n",
    "    print(customers_data.head())\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df1076-a5d6-4762-8a1f-f2a30123a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Daten von der JSONPlaceholder API abrufen\n",
    "response = requests.get('https://jsonplaceholder.typicode.com/users')\n",
    "\n",
    "# Überprüfen, ob die Anfrage erfolgreich war\n",
    "if response.status_code == 200:\n",
    "    users_data = response.json()\n",
    "    users_df = pd.DataFrame(users_data)\n",
    "    print(users_df.head())\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd8e645-a5ed-4224-80dc-bb55454b002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler bei der Anfrage: 401\n"
     ]
    }
   ],
   "source": [
    "# zahlungspflichtig!\n",
    "\n",
    "import requests\n",
    "\n",
    "# Ersetze 'your_api_key' durch deinen OpenWeatherMap API-Schlüssel\n",
    "api_key = 'your_api_key'\n",
    "city = 'Berlin'\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}'\n",
    "\n",
    "# Wetterdaten abrufen\n",
    "response = requests.get(url)\n",
    "\n",
    "# Überprüfen, ob die Anfrage erfolgreich war\n",
    "if response.status_code == 200:\n",
    "    weather_data = response.json()\n",
    "    print(weather_data)\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e51ce2-ed61-43fa-a44f-12ac5a791ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id symbol  current_price     market_cap\n",
      "0      bitcoin    btc      67293.000  1330070002030\n",
      "1     ethereum    eth       2608.590   314016997202\n",
      "2       tether   usdt          1.001   120056206419\n",
      "3  binancecoin    bnb        591.490    86278115429\n",
      "4       solana    sol        150.620    70752025139\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Daten von der CoinGecko API abrufen\n",
    "response = requests.get('https://api.coingecko.com/api/v3/coins/markets', \n",
    "                        params={'vs_currency': 'usd', 'order': 'market_cap_desc', 'per_page': 10})\n",
    "\n",
    "# Überprüfen, ob die Anfrage erfolgreich war\n",
    "if response.status_code == 200:\n",
    "    crypto_data = response.json()\n",
    "    crypto_df = pd.DataFrame(crypto_data)\n",
    "    print(crypto_df[['id', 'symbol', 'current_price', 'market_cap']].head())\n",
    "else:\n",
    "    print(f\"Fehler bei der Anfrage: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cdce5-07e6-4946-be85-ec26d74258f7",
   "metadata": {},
   "source": [
    "## Dateibasierte Speicherung\n",
    "\n",
    "Dateibasierte Daten wie CSV oder Excel werden häufig zur Speicherung und Übertragung von Daten verwendet.\n",
    "\n",
    "\n",
    "Beispiel in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69824dac-f22a-4b50-bddd-e8a1967fc511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id    product  sales_amount  sales_date\n",
      "0            1  Product_A           120  2023-01-01\n",
      "1            2  Product_B           150  2023-01-02\n",
      "2            3  Product_C           130  2023-01-03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV-Datei laden\n",
    "csv_data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Daten anzeigen\n",
    "print(csv_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7eaef-7aa7-4ce4-98a7-302209a53dc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Techniken zur Kombination von Datenquellen\n",
    "\n",
    "Es gibt mehrere Techniken, um Daten aus verschiedenen Quellen zu kombinieren:\n",
    "\n",
    "1. **Datenzusammenführung (Merge/Join)** <br>\n",
    "   Eine häufig verwendete Methode, bei der Daten basierend auf gemeinsamen Attributen (z. B. einem eindeutigen Identifikator wie einer Kundennummer) kombiniert werden.\n",
    "\n",
    "    - Inner Join: Nur Datensätze, die in beiden Quellen vorhanden sind, werden kombiniert.\n",
    "    - Outer Join: Beinhaltet alle Datensätze aus beiden Quellen, auch wenn eine Quelle keine Übereinstimmung aufweist.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **Datenkonsolidierung** <br>\n",
    "   Daten aus mehreren Quellen werden in einer einzigen Datenbank oder einem Datensatz konsolidiert, um Redundanzen zu vermeiden und die Analyse zu vereinfachen.\n",
    "\n",
    "<br>\n",
    "\n",
    "3. **ETL (Extract, Transform, Load)** <br>\n",
    "   Ein Prozess, bei dem Daten aus mehreren Quellen extrahiert, in eine einheitliche Struktur transformiert und dann in eine zentrale Datenbank oder ein Data Warehouse geladen werden.\n",
    "\n",
    "<br>\n",
    "\n",
    "4. **Datenfusion** <br>\n",
    "   Zusammenführen von Daten aus verschiedenen Quellen, die sich teilweise überschneiden, aber nicht identisch sind.\n",
    "   Oft verwendet für die Kombination unterschiedlicher Datentypen (z. B. numerische und textuelle Daten).\n",
    "\n",
    "<br>\n",
    "\n",
    "5. **Datenharmonisierung** <br>\n",
    "   Anpassung von Daten aus verschiedenen Quellen, damit sie eine einheitliche Struktur und Bedeutung haben (z. B. Standardisierung von Formaten oder Einheiten).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2fbf3-b493-469f-a62a-856cc3280522",
   "metadata": {},
   "source": [
    "# Warum ist es wichtig, Daten aus mehreren Quellen zu kombinieren?\n",
    "\n",
    "Die Quellenkombination ermöglicht tiefere und genauere Erkenntnisse, die durch die Analyse einzelner Datenquellen nicht erreicht werden können.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **Umfassendere Perspektive**\n",
    "- Daten aus nur einer Quelle bieten oft nur begrenzten oder isolierten Blick auf Problem oder Fragestellung\n",
    "- durch Kombination mehrerer Datenquellen kann ein vollständigeres Bild der Situation entstehen\n",
    "- verschiedene Datenquellen können unterschiedliche Aspekte desselben Phänomens abdecken -> lässt umfassendere Analyse zu\n",
    "- **Beispiel**<br>\n",
    "  Ein Unternehmen könnte Verkaufsdaten, Marketingdaten und Kundenzufriedenheitsdaten kombinieren, um zu verstehen, wie Werbekampagnen den Umsatz und die Kundenzufriedenheit beeinflussen.\n",
    "\n",
    "<br>\n",
    "\n",
    " 2. **Erhöhte Datenqualität**\n",
    "- Inkonsistenzen, Fehler oder Lücken in den einzelnen Datenquellen können erkannt und behoben werden\n",
    "- eine Quelle könnte fehlende Daten liefern, während eine andere Quelle diese Information enthält\n",
    "- erhöht Zuverlässigkeit und Genauigkeit der analysierten Daten\n",
    "- **Beispiel**<br>\n",
    "  Fehlende demografische Informationen in einer Kundendatenbank könnten durch eine externe Quelle wie Social-Media-Daten ergänzt werden, um ein vollständiges Kundenprofil zu erstellen.\n",
    "\n",
    "<br>\n",
    "\n",
    " 3. **Erweiterung des Analysepotenzials**\n",
    "- neue Analysewege, die mit einer einzelnen Quelle nicht möglich wären\n",
    "- Möglichkeiten zur Analyse von Beziehungen, Korrelationen und Mustern entsehen, die nur durch Zusammenfügen von Daten aus verschiedenen Quellen erkennbar werden\n",
    "- **Beispiel**<br>\n",
    "  Das Kombinieren von Web-Traffic-Daten mit Verkaufszahlen ermöglicht es, zu analysieren, wie sich bestimmte Nutzerinteraktionen auf der Website auf Kaufentscheidungen auswirken.\n",
    "\n",
    "<br>\n",
    "\n",
    " 4. **Bessere Entscheidungsgrundlagen**\n",
    "- fundiertere Entscheidungsgrundlage, die mehr Aspekte und Faktoren berücksichtigt\n",
    "- reduziert das Risiko, falsche oder voreilige Entscheidungen zu treffen\n",
    "- **Beispiel**<br>\n",
    "  Ein Unternehmen könnte Finanzdaten, Kundendaten und Markttrends zusammenführen, um fundierte Entscheidungen über Produktentwicklungen oder Investitionen zu treffen.\n",
    "\n",
    "<br>\n",
    "\n",
    " 5. **Erkennung von Mustern und Trends**\n",
    "- kann helfen, Muster und Trends zu erkennen, die in einer einzelnen Quelle möglicherweise nicht erkennbar sind\n",
    "- besonders nützlich beim maschinellen Lernen, wo die Kombination verschiedener Merkmale (Features) das Training genauerer Modelle ermöglicht\n",
    "- **Beispiel**<br>\n",
    "  Im Gesundheitswesen könnten Patientendaten aus Krankenakten, genetische Informationen und Umweltfaktoren kombiniert werden, um neue Zusammenhänge zwischen Lebensstil und Krankheitsentwicklung zu identifizieren.\n",
    "\n",
    "<br>\n",
    "\n",
    " 6. **Kontextualisierung von Daten**\n",
    "- Daten aus einer Quelle oft schwer zu interpretieren, wenn sie isoliert betrachtet werden\n",
    "- besserer Kontext durch Kombination mit weiteren Informationen, der zu präziseren Schlussfolgerungen führt\n",
    "- **Beispiel**<br>\n",
    "  Verkaufszahlen könnten zusammen mit regionalen Wirtschaftsdaten kombiniert werden, um den Einfluss lokaler wirtschaftlicher Bedingungen auf den Umsatz zu analysieren.\n",
    "\n",
    "<br>\n",
    "\n",
    " 7. **Identifikation von Anomalien**\n",
    "- Abweichungen oder Ausreißer, die nur in einer Quelle auftreten, können leichter erkannt werden\n",
    "- nützlich, um potenzielle Probleme oder Anomalien in den Daten frühzeitig zu identifizieren\n",
    "- **Beispiel**<br>\n",
    "  Wenn die Verkaufsdaten einer Filiale stark von den Personaldaten oder den Kundenzufriedenheitswerten abweichen, könnte dies auf ein betriebliches Problem hinweisen, das sonst unentdeckt geblieben wäre.\n",
    "\n",
    "<br>\n",
    "\n",
    " 8. **Effizienzsteigerung**\n",
    "- Redundanzen werden reduziert und Prozesse optimiert\n",
    "- Analysen und Berichte können automatisiert und effizienter gestaltet werden\n",
    "- **Beispiel**<br>\n",
    "  Ein Logistikunternehmen könnte Lagerbestandsdaten, Verkehrsdaten und Wetterdaten kombinieren, um Lieferkettenprozesse zu optimieren und Lieferzeiten zu reduzieren.\n",
    "\n",
    "<br>\n",
    "\n",
    " 9. **Innovationsförderung**\n",
    "- neue Ideen und Innovationen können entstehen\n",
    "- kann völlig neue Perspektiven bieten und die Entwicklung neuer Produkte, Dienstleistungen oder Geschäftsmodelle unterstützen\n",
    "- **Beispiel**<br>\n",
    "  Ein Tech-Startup könnte IoT-Daten (z. B. Sensordaten von Smart-Geräten) mit maschinellen Lernmodellen kombinieren, um innovative Lösungen für das Smart Home zu entwickeln.\n",
    "\n",
    "<br>\n",
    "\n",
    " 10. **Skalierbare Analysen**\n",
    "- skalierbare Modelle und Analysen können erstellt werden\n",
    "- besonders wichtig in großen, dynamischen Umgebungen, in denen Daten aus verschiedenen Systemen ständig aktualisiert und erweitert werden müssen\n",
    "- **Beispiel**<br>\n",
    "  In der Finanzbranche werden Echtzeit-Marktdaten mit historischen Daten kombiniert, um Algorithmen für den Hochfrequenzhandel zu trainieren.\n",
    "\n",
    "<br>\n",
    "\n",
    " 11. **Bessere Personaliserung**\n",
    "- personalisierte Produkte, Dienstleistungen oder Kampagnen können entwickelt werden\n",
    "- besonders nützlich im Marketing und in der Kundenbetreuung, um individuelle Bedürfnisse und Präferenzen besser zu verstehen\n",
    "- **Beispiel**<br>\n",
    "  Ein E-Commerce-Unternehmen könnte das Kaufverhalten, die Browsing-Historie und die demografischen Daten eines Kunden zusammenführen, um gezielte Produktvorschläge zu machen.\n",
    "\n",
    "<br>\n",
    "\n",
    " 12. **Compliance und Risikoüberwachung**\n",
    "- Unternehmen sind oft verpflichtet, verschiedene Datenquellen zusammenzuführen, um regulatorische Anforderungen zu erfüllen oder Risiken zu überwachen\n",
    "- durch die Aggregation von Daten aus verschiedenen operativen und finanziellen Systemen können Unternehmen sicherstellen, dass sie den gesetzlichen Anforderungen entsprechen\n",
    "- **Beispiel**<br>\n",
    "  In der Finanzbranche müssen oft Daten aus verschiedenen Abteilungen (z. B. Compliance, Risiko, Finanzen) kombiniert werden, um umfassende regulatorische Berichte zu erstellen.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ad8a5-d4d6-4b5e-a4dd-c9ecc9cb5317",
   "metadata": {},
   "source": [
    "# Beispiel: Integration von Daten aus verschiedenen Quellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85f024f-dce5-40b5-94fa-46b347be6b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id    product  sales_amount  sales_date customer_name  \\\n",
      "0            1  Product_A           120  2023-01-01      John Doe   \n",
      "1            2  Product_B           150  2023-01-02    Jane Smith   \n",
      "2            3  Product_C           130  2023-01-03     Tom Brown   \n",
      "\n",
      "              email  \n",
      "0  john@example.com  \n",
      "1  jane@example.com  \n",
      "2   tom@example.com  \n"
     ]
    }
   ],
   "source": [
    "# Installation von openpyxl notwendig\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Beispieldatenquelle 1 (CSV)\n",
    "data1 = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Beispieldatenquelle 2 (Excel)\n",
    "data2 = pd.read_excel('customer_data.xlsx')\n",
    "\n",
    "# Daten kombinieren (nach einer gemeinsamen Spalte)\n",
    "merged_data = pd.merge(data1, data2, on='customer_id')\n",
    "\n",
    "# Kombinierte Daten anzeigen\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93143d4d-7493-4bb0-8f3e-7ddb47b57069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id    product  sales_amount         name              email\n",
      "0            1  Product_A           120     John Doe   john@example.com\n",
      "1            2  Product_B           150   Jane Smith   jane@example.com\n",
      "2            3  Product_C           130  Emily Davis  emily@example.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Datenquelle 1: Verkaufsdaten\n",
    "sales_data = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'product': ['Product_A', 'Product_B', 'Product_C', 'Product_D'],\n",
    "    'sales_amount': [120, 150, 130, 170]\n",
    "})\n",
    "\n",
    "# Datenquelle 2: Kundendaten (API oder CSV)\n",
    "customer_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 5],  # customer_id und id sind unterschiedliche Schlüssel\n",
    "    'name': ['John Doe', 'Jane Smith', 'Emily Davis', 'Chris Brown'],\n",
    "    'email': ['john@example.com', 'jane@example.com', 'emily@example.com', 'chris@example.com']\n",
    "})\n",
    "\n",
    "# Anpassen der Schlüssel für die Zusammenführung\n",
    "customer_data.rename(columns={'id': 'customer_id'}, inplace=True)\n",
    "\n",
    "# Daten zusammenführen (inner join)\n",
    "merged_data = pd.merge(sales_data, customer_data, on='customer_id', how='inner')\n",
    "\n",
    "# Zusammengeführte Daten anzeigen\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95e3e2-e2da-48d9-b68c-846e81230a9e",
   "metadata": {},
   "source": [
    "1. Daten  sales.db aufrufen\n",
    "2. Daten market_data.csv aufrufen\n",
    "3. Daten mergen mit der Spalte 'product' \n",
    "4. Daten ausgeben\n",
    "5. Durchschnittlicher Verkaufsbetrag pro Produkt ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedd6dff-c3f8-41c2-90de-4abadeb445d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id    product  sales_amount  sales_date\n",
      "0            1  Product_A         120.0  2023-01-01\n",
      "1            2  Product_B         150.0  2023-01-02\n",
      "2            3  Product_C         130.0  2023-01-03\n",
      "3            4  Product_D         170.0  2023-01-04\n",
      "   customer_id    product  sales_amount  sales_date  market_price market_trend\n",
      "0            1  Product_A         120.0  2023-01-01         125.0           up\n",
      "1            2  Product_B         150.0  2023-01-02         155.0         down\n",
      "2            3  Product_C         130.0  2023-01-03         135.0           up\n",
      "3            4  Product_D         170.0  2023-01-04         175.0       stable\n",
      "product\n",
      "Product_A    120.0\n",
      "Product_B    150.0\n",
      "Product_C    130.0\n",
      "Product_D    170.0\n",
      "Name: sales_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Verbindung zur Datenbank herstellen und Daten abrufen\n",
    "conn = sqlite3.connect('sales.db')\n",
    "sales_data = pd.read_sql(\"SELECT * FROM sales_data\", conn)\n",
    "\n",
    "\n",
    "print(sales_data.head())\n",
    "# CSV-Datei mit Marktdaten laden\n",
    "market_data = pd.read_csv('market_data.csv')\n",
    "\n",
    "# Daten zusammenführen\n",
    "# Angenommen, alle Datensätze enthalten 'customer_id'\n",
    "merged_data = pd.merge(sales_data, market_data, on='product')\n",
    "\n",
    "# Zusammengeführte Daten anzeigen\n",
    "print(merged_data.head())\n",
    "\n",
    "# Datenanalyse: Durchschnittlicher Verkaufsbetrag pro Produkt\n",
    "average_sales = merged_data.groupby('product')['sales_amount'].mean()\n",
    "print(average_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81781e-73fb-44f4-aa46-d59c362d919e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
