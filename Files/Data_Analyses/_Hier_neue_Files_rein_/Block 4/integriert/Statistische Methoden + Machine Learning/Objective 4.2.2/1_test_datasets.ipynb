{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25894e9-acd9-45e3-85d3-e86b4e8eeacf",
   "metadata": {},
   "source": [
    "**Testdatensätze** spielen beim maschinellen Lernen eine entscheidende Rolle bei der **Bewertung und Validierung von Modellen.**\n",
    "\n",
    "Um die Bedeutung dieser Datensätze im Kontext des Modelltrainings zu verstehen, schauen wir uns die **typischen Phasen des maschinellen Lernens** an:\n",
    "\n",
    "1. Datensammlung\n",
    "2. Vorverarbeitung\n",
    "3. Modelltraining\n",
    "4. Modellvalidierung\n",
    "5. Modellbewertung\n",
    "\n",
    "https://datasolut.com/wiki/trainingsdaten-und-testdaten-machine-learning/\n",
    "\n",
    "Er ermöglicht eine objektive Bewertung der Generalisierungsfähigkeit des Modells und schützt vor Overfitting sowie vor irreführenden Bewertungen durch Datenlecks. \n",
    "\n",
    "Die sorgfältige Verwendung von Testdaten ist daher ein zentraler Bestandteil der Entwicklung leistungsfähiger und robuster maschineller Lernmodelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6112d-228b-4987-9eb6-3749de755013",
   "metadata": {},
   "source": [
    "# Syllabus\n",
    "\n",
    "Understand the role of test datasets in validating the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6eb43-689e-4d75-8791-ac3da8565cb1",
   "metadata": {},
   "source": [
    "---\n",
    "# Aufteilung der Daten: Trainings- und Testdatensätze\n",
    "\n",
    "\n",
    "Beim maschinellen Lernen wird ein Datensatz in der Regel in zwei oder drei Teile aufgeteilt:\n",
    "\n",
    "\n",
    "- **Trainingsdatensatz**:<br>\n",
    "Wird verwendet, um das Modell zu trainieren.<br>\n",
    "Hier lernt das Modell die Muster und Beziehungen zwischen den Eingabe- und Zielvariablen.\n",
    "<br>\n",
    "\n",
    "- **Validierungsdatensatz** (optional):<br>\n",
    "Wird genutzt, um während des Trainings **Hyperparameter** wie die Lernrate oder die Modellarchitektur abzustimmen und eine Überanpassung (**Overfitting**) zu verhindern.<br>\n",
    "Er wird während des Trainings zur Feinabstimmung des Modells verwendet.\n",
    "<br>\n",
    "\n",
    "- **Testdatensatz**:<br>\n",
    "Wird vollständig vom Training und der Hyperparameteroptimierung getrennt gehalten und dient ausschließlich dazu, die endgültige Leistung des Modells zu bewerten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469544a6-ac93-4702-ab87-7dcac51ec5c4",
   "metadata": {},
   "source": [
    "---\n",
    "# Warum braucht man einen Testdatensatz?\n",
    "\n",
    "\n",
    "Der Testdatensatz wird benötigt, um die **Generalisierungsfähigkeit** des Modells zu beurteilen. \n",
    "\n",
    "Generalisierung bedeutet, wie gut das Modell auf unbekannte Daten reagiert, d.h. auf Daten, die es noch nicht gesehen hat.<br>\n",
    "Ohne einen Testdatensatz könnte man das Modell nur auf den Trainingsdaten evaluieren, was jedoch zu überoptimistischen Ergebnissen führen würde.\n",
    "\n",
    "- **Überanpassung vermeiden**:<br>\n",
    "Wenn ein Modell zu stark auf den Trainingsdaten \"lernt\", also sehr spezifische Muster und Rauschen der Trainingsdaten erkennt, anstatt die zugrunde liegenden allgemeinen Muster, spricht man von **Overfitting**.<br>\n",
    "Das Modell funktioniert dann auf den Trainingsdaten gut, versagt aber bei neuen, unbekannten Daten.<br>\n",
    "Der Testdatensatz stellt sicher, dass das Modell nicht nur auf den Trainingsdaten, sondern auch auf neuen, ungesehenen Daten gute Leistungen erbringt.\n",
    "  \n",
    "- **Objektive Leistungsmessung**:<br>\n",
    "Da der Testdatensatz während des Trainings unberührt bleibt, bietet er eine objektive Möglichkeit, die tatsächliche Leistung des Modells zu bewerten.<br>\n",
    "Er spiegelt, wie das Modell in der realen Welt auf neue Daten reagieren würde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93eed4-ac15-4f90-9472-1fbb1f2992c3",
   "metadata": {},
   "source": [
    "---\n",
    "# Leistungsmessung und -bewertung\n",
    "\n",
    "\n",
    "Typischerweise werden für die Bewertung (Validierung) des Modells verschiedene Metriken auf dem Testdatensatz verwendet.<br>\n",
    " Die Wahl der Metrik hängt vom Problem ab, z. B.:\n",
    "- **Für Regressionsprobleme**:<br>\n",
    "Metriken wie der mittlere quadratische Fehler (MSE), der mittlere absolute Fehler (MAE) oder der R²-Wert.\n",
    "<br>\n",
    "\n",
    "- **Für Klassifikationsprobleme**:<br>\n",
    "Genauigkeit (Accuracy), Präzision, Recall, F1-Score oder die ROC-AUC-Kurve.\n",
    "\n",
    "Diese Metriken zeigen, wie gut das Modell neue Daten klassifiziert oder Vorhersagen macht. Da der Testdatensatz bisher unbekannt war, liefert dies eine faire Einschätzung der Modellleistung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27d835-8790-44c9-997c-e4bc824f5357",
   "metadata": {},
   "source": [
    "---\n",
    "# Schutz vor Datenlecks\n",
    "Ein weiteres wichtiges Konzept ist das sogenannte \"Datenleck\" (Data Leakage). Dies tritt auf, wenn Informationen aus dem Testdatensatz versehentlich in den Trainingsprozess gelangen, was zu unrealistisch guten Leistungen führt.\n",
    "\n",
    "Ein sauberer Testdatensatz stellt sicher, dass keine solchen Lecks auftreten und die Bewertung des Modells nicht durch irreführende Daten beeinflusst wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c3541-3121-44c1-ae8d-eb1f8fc01349",
   "metadata": {},
   "source": [
    "---\n",
    "# Train-Test-Split und Cross-Validation\n",
    "\n",
    "**Train-Test-Split**:<br>\n",
    "Eine gängige Methode zur Aufteilung der Daten, bei dem der Datensatz z.B. im Verhältnis 80:20 oder 70:30 aufgeteilt wirdy<br>\n",
    "(80% für das Training, 20% für den Test). \n",
    "\n",
    "Um jedoch sicherzustellen, dass das Modell robust gegenüber verschiedenen Trainingsdaten ist und keine Abhängigkeit von einer bestimmten Datenaufteilung entsteht, wird oft **Cross-Validation** verwendet. \n",
    "\n",
    "Dabei wird der Datensatz in mehrere Teilmengen aufgeteilt, und das Modell wird mehrmals trainiert und getestet, wobei jedes Mal eine andere Teilmenge als Testdatensatz dient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5072faa-74c1-4bdd-9f8c-13814b91209a",
   "metadata": {},
   "source": [
    "---\n",
    "# Testdatensatz als Stellvertreter für reale Daten\n",
    "\n",
    "Schließlich dient der Testdatensatz als Proxy für reale Daten, denen das Modell in Produktionsumgebungen begegnen wird. \n",
    "\n",
    "Er repräsentiert, wie das Modell auf Daten reagieren wird, die in der Praxis auftreten, und hilft dabei, sicherzustellen, dass das Modell nicht nur auf den Trainingsdaten gut abschneidet, sondern auch in der Realität nützliche und genaue Vorhersagen liefert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b5e7c-90c1-4ee1-9fd4-c7dad2f91189",
   "metadata": {},
   "source": [
    "---\n",
    "# praktische Anwendung in Python\n",
    "\n",
    "## Beispiel 1: Iris-Datensatz\n",
    "\n",
    "Das folgende Beispiel soll zeigen, wie man Testdatensätze verwendet, um die Leistung eines Modells zu bewerten. \n",
    "\n",
    "In diesem Fall wird die Bibliothek **scikit-learn** verwendet, um ein einfaches Klassifikationsproblem mit einem **Train-Test-Split** zu implementieren. Dabei werden wir das Modell auf den Trainingsdaten trainieren und die Modellleistung auf den Testdaten bewerten.\n",
    "\n",
    "Wir verwenden hier den **Iris-Datensatz**, der oft als Beispiel für Klassifikationsaufgaben verwendet wird.<br>\n",
    "Das Modell wird ein **Logistic Regression**-Modell sein.\n",
    "\n",
    "### Datenaufteilung und Modelltraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b8c0b8-9cc0-4a74-b1ce-ed528485fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit auf den Testdaten: 1.00\n",
      "Klassifikationsbericht:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bibliotheken importieren\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Den Iris-Datensatz laden\n",
    "iris = load_iris()\n",
    "X = iris.data  # Merkmale (Features)\n",
    "y = iris.target  # Zielvariable (Target)\n",
    "\n",
    "# Daten in Trainings- und Testdatensätze aufteilen\n",
    "# Hier 80% Training und 20% Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modell erstellen und auf den Trainingsdaten trainieren\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modell auf den Testdaten anwenden (Vorhersagen treffen)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Modellleistung bewerten (Genauigkeit und weitere Metriken)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Genauigkeit auf den Testdaten: {accuracy:.2f}\")\n",
    "\n",
    "# Detaillierterer Bericht über die Modellleistung\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c046d0-8e68-4bcc-9eb7-9fbe65e50d8a",
   "metadata": {},
   "source": [
    "### Erläuterung des Codes\n",
    "\n",
    "\n",
    "   \n",
    "1. **Train-Test-Split**:<br>\n",
    "Mit der Funktion `train_test_split()` wird der Datensatz in zwei Teile aufgeteilt:\n",
    "\n",
    "   - `X_train`, `y_train`: Diese Daten werden für das Modelltraining verwendet (80% der Daten).<br>\n",
    "   - `X_test`, `y_test`: Diese Daten werden für die Bewertung des Modells verwendet (20% der Daten).\n",
    "<br>\n",
    "\n",
    "2. **Modell erstellen und trainieren**:<br>\n",
    "Hier verwenden wir die logistische Regression (`LogisticRegression`) und trainieren das Modell auf den Trainingsdaten mit der Methode `fit()`.\n",
    "\n",
    "3. **Vorhersagen auf dem Testdatensatz**:<br>\n",
    "Das trainierte Modell wird genutzt, um Vorhersagen auf den Testdaten zu treffen (`predict()`).\n",
    "\n",
    "4. **Modellbewertung**:<br>\n",
    "\n",
    "   - Die Genauigkeit wird mit der Funktion `accuracy_score()` berechnet.\n",
    "   - Der detaillierte Klassifikationsbericht (`classification_report`) zeigt zusätzliche Metriken wie **Precision**, **Recall** und **F1-Score** an, um die Modellleistung für jede Klasse zu analysieren.\n",
    "\n",
    "\n",
    "\n",
    "In diesem Beispiel erzielt das Modell auf den Testdaten eine Genauigkeit von 100%, was darauf hindeutet, dass das Modell die Daten gut generalisieren kann. Dies kann jedoch bei komplexeren Datensätzen oder Problemen seltener der Fall sein. Normalerweise erhält man Genauigkeiten, die weniger als 100% betragen, was dann eine genauere Analyse erfordert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3058d-44ca-4254-980d-7f24fbb416f7",
   "metadata": {},
   "source": [
    "## Beispiel 2: Titanic-Datensatz\n",
    "\n",
    "### Datenaufteilung und Modelltraining\n",
    "\n",
    "In diesem Abschnitt werden wir einen Datensatz in Trainings- und Testdaten aufteilen, ein Modell trainieren und die Leistung auf den Testdaten bewerten.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Abschnitt 1: Setup**\n",
    "\n",
    "Zunächst importieren wir die notwendigen Bibliotheken und laden den Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab264b45-f458-42af-8517-377fc551a222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age     Fare  Survived\n",
       "0       3  22.0   7.2500         0\n",
       "1       1  38.0  71.2833         1\n",
       "2       3  26.0   7.9250         1\n",
       "3       1  35.0  53.1000         1\n",
       "4       3  35.0   8.0500         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Beispiel: Laden eines Datensatzes (Titanic-Datensatz)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "# Datenaufbereitung: Auswahl der relevanten Features und Zielvariable\n",
    "df = df[['Pclass', 'Age', 'Fare', 'Survived']].dropna()\n",
    "\n",
    "# Features und Zielvariable definieren\n",
    "X = df[['Pclass', 'Age', 'Fare']]\n",
    "y = df['Survived']\n",
    "\n",
    "# Anzeigen der ersten Zeilen des Datensatzes\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d3eb2-13fa-4148-a418-a79de4c89742",
   "metadata": {},
   "source": [
    "**Abschnitt 2: Aufteilen der Daten in Trainings- und Testsets**\n",
    "\n",
    "Hier teilen wir den Datensatz in einen Trainingssatz und einen Testdatensatz auf. \n",
    "\n",
    "Typischerweise verwendet man 70-80% der Daten zum Training und 20-30% zum Testen.\n",
    "\n",
    "Erklärung:<br>\n",
    "Die `train_test_split-Methode` von sklearn wird verwendet, um den Datensatz in zufällig ausgewählte Trainings- und Testdaten zu unterteilen. Das `random_state` sorgt dafür, dass die Ergebnisse reproduzierbar sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3318a1e-bdbd-4684-b9f5-55bb420c5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: (571, 3), Testdaten: (143, 3)\n"
     ]
    }
   ],
   "source": [
    "# Aufteilen der Daten in Trainings- und Testsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Anzeigen der Dimensionen der aufgeteilten Daten\n",
    "print(f\"Trainingsdaten: {X_train.shape}, Testdaten: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af549539-291e-477b-9681-180680b0c759",
   "metadata": {},
   "source": [
    "**Abschnitt 3: Trainieren eines Machine-Learning-Modells**\n",
    "\n",
    "Als Beispiel verwenden wir die Logistische Regression, um ein Modell zu trainieren, das vorhersagen soll, ob ein Passagier die Titanic-Katastrophe überlebt hat.\n",
    "\n",
    "Erklärung:<br>\n",
    "Hier trainieren wir das Modell auf den Trainingsdaten (X_train und y_train) und testen dann, wie gut das Modell auf den Testdaten (X_test) funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acb1599-2ce6-4c97-b5ce-be65b30f289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.09675973 -0.04794221  0.00373808]]\n",
      "Testgenauigkeit des Modells: 67.13%\n"
     ]
    }
   ],
   "source": [
    "# Erstellen und Trainieren eines Logistischen Regressionsmodells\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.coef_)\n",
    "# Vorhersagen auf den Testdaten\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Berechnen der Genauigkeit des Modells\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testgenauigkeit des Modells: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68b9fd-2782-420d-9625-6edbdcf5da36",
   "metadata": {},
   "source": [
    "**Abschnitt 4: Bedeutung der Generalisierung und Vermeidung von Overfitting**\n",
    "\n",
    "Ein Modell, das auf den Trainingsdaten sehr gut funktioniert, aber auf den Testdaten schlecht abschneidet, überanpasst möglicherweise die Trainingsdaten. Um dies zu verhindern, ist es wichtig, ein unvoreingenommenes Testset zu verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e359f-3dbe-49cb-ad3b-f7af315dba6d",
   "metadata": {},
   "source": [
    "# Generalisierung und Overfitting\n",
    "Ein Modell, das zu gut auf die Trainingsdaten abgestimmt ist, hat möglicherweise die spezifischen Muster in den Trainingsdaten gelernt, aber kann nicht auf neue Daten generalisieren.\n",
    "\n",
    "Durch die Verwendung eines separaten Testdatensatzes können wir die **Generalisierungsfähigkeit** eines Modells bewerten. Eine hohe Genauigkeit auf den Trainingsdaten, aber eine schlechte Leistung auf den Testdaten, weist auf Overfitting hin.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
